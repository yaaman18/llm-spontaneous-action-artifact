# è«–æ–‡åé›†ãƒ»å¤‰æ›ãƒ„ãƒ¼ãƒ«ä½¿ç”¨ä¾‹

ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã¯ã€è«–æ–‡åé›†ãƒ»å¤‰æ›ãƒ„ãƒ¼ãƒ«ã®å…·ä½“çš„ãªä½¿ç”¨ä¾‹ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚

## ğŸ“š åŸºæœ¬çš„ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

### 1. è«–æ–‡æ¤œç´¢ãƒ»åé›† â†’ 2. PDFå¤‰æ› â†’ 3. ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³æ´»ç”¨

```mermaid
graph LR
    A[è«–æ–‡æ¤œç´¢] --> B[PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰] --> C[ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å¤‰æ›] --> D[ç ”ç©¶æ´»ç”¨]
```

## ğŸ” è«–æ–‡åé›†ã®ä½¿ç”¨ä¾‹

### ã‚±ãƒ¼ã‚¹1: ç‰¹å®šã®è‘—è€…ã®è«–æ–‡ã‚’åé›†

```bash
# Maxwell Ramsteadã®è«–æ–‡ã‚’æ¤œç´¢ãƒ»åé›†
cd /path/to/institute/tools/paper-collector
python search_ramstead.py
```

**å®Ÿè¡Œçµæœä¾‹:**
```
=== Searching papers by Ramstead ===

Found 10 papers on Google Scholar

--- Paper 1 ---
Title: Neural and phenotypic representation under the free-energy principle
Authors: MJD Ramstead, C Hesp, A Tschantz, R Smithâ€¦
Published: 2021

åé›†å®Œäº†ï¼
åé›†ã—ãŸè«–æ–‡æ•°: 10
ä¿å­˜å…ˆ: /institute/library/author_search/Ramstead
```

### ã‚±ãƒ¼ã‚¹2: æ„è­˜ç ”ç©¶è«–æ–‡ã®åŒ…æ‹¬çš„åé›†

```bash
# æ„è­˜ç ”ç©¶ã«é–¢ã™ã‚‹ã™ã¹ã¦ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢
python paper_collector.py
```

**æ¤œç´¢ã•ã‚Œã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:**
- consciousness
- awareness  
- phenomenology
- qualia
- integrated information theory (IIT)
- global workspace theory
- neural correlates consciousness (NCC)
- subjective experience

### ã‚±ãƒ¼ã‚¹3: ã‚«ã‚¹ã‚¿ãƒ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢

```python
from paper_collector import PaperCollector

# ã‚«ã‚¹ã‚¿ãƒ æ¤œç´¢
collector = PaperCollector("custom_papers")

# Free Energy Principleã«é–¢ã™ã‚‹è«–æ–‡
papers = collector.search_arxiv("free energy principle", max_results=20)

# ç‰¹å®šã®è‘—è€… + ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
papers = collector.search_arxiv('au:"Karl Friston" AND all:consciousness', max_results=15)

# Google Scholarã§ã‚‚æ¤œç´¢
scholar_papers = collector.search_google_scholar(
    "active inference consciousness phenomenology", 
    num_results=10
)
```

## ğŸ“„ PDFå¤‰æ›ã®ä½¿ç”¨ä¾‹

### ã‚±ãƒ¼ã‚¹1: åé›†ã—ãŸè«–æ–‡ã®PDFã‚’ä¸€æ‹¬å¤‰æ›

```bash
# Ramsteadã®è«–æ–‡ã‚’ã™ã¹ã¦ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã«å¤‰æ›
python batch_convert.py --author "Ramstead"
```

**å®Ÿè¡Œçµæœä¾‹:**
```
ğŸ“Š Batch Conversion Results:
Directories processed: 1/1
Total files: 3
Successful conversions: 3
Failed conversions: 0
Success rate: 100.0%

ğŸ“ Converted directories:
  - Ramstead: 3/3 files
```

### ã‚±ãƒ¼ã‚¹2: ç‰¹å®šã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®PDFã‚’å¤‰æ›

```bash
# ç‰¹å®šã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æŒ‡å®š
python batch_convert.py --directory "/institute/library/author_search/Ramstead/pdfs"
```

### ã‚±ãƒ¼ã‚¹3: å˜ä¸€PDFãƒ•ã‚¡ã‚¤ãƒ«ã®å¤‰æ›

```bash
# 1ã¤ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¤‰æ›
python pdf_to_markdown.py /path/to/pdfs --single_file consciousness_paper.pdf
```

### ã‚±ãƒ¼ã‚¹4: ã™ã¹ã¦ã®åé›†æ¸ˆã¿PDFã‚’ä¸€æ‹¬å¤‰æ›

```bash
# ç ”ç©¶æ‰€ãƒ©ã‚¤ãƒ–ãƒ©ãƒªå†…ã®ã™ã¹ã¦ã®PDFã‚’å¤‰æ›
python batch_convert.py
```

**å®Ÿè¡Œçµæœä¾‹:**
```
ğŸ“Š Batch Conversion Results:
Directories processed: 5/5
Total files: 47
Successful conversions: 45
Failed conversions: 2
Success rate: 95.7%

ğŸ“ Converted directories:
  - Ramstead: 10/10 files
  - collected_papers: 20/22 files
  - consciousness_lab: 15/15 files
```

## ğŸ”§ ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‹ã‚‰ã®ä½¿ç”¨ä¾‹

### Python ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã®è‡ªå‹•åŒ–

```python
#!/usr/bin/env python3
"""
æ„è­˜ç ”ç©¶è«–æ–‡ã®è‡ªå‹•åé›†ãƒ»å¤‰æ›ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
"""

from paper_collector import PaperCollector
from pdf_to_markdown import PDFToMarkdownConverter
from pathlib import Path
import time

def automated_research_pipeline():
    """ç ”ç©¶è«–æ–‡ã®è‡ªå‹•å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""
    
    # 1. è«–æ–‡åé›†
    print("ğŸ” Starting paper collection...")
    collector = PaperCollector("consciousness_research_2025")
    
    # ç‰¹å®šã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢
    keywords = [
        "consciousness neural correlates",
        "phenomenology computational",
        "qualia artificial intelligence",
        "integrated information theory 2024"
    ]
    
    all_papers = []
    for keyword in keywords:
        papers = collector.search_arxiv(keyword, max_results=10)
        all_papers.extend(papers)
        time.sleep(2)  # APIåˆ¶é™å¯¾ç­–
    
    print(f"ğŸ“š Collected {len(all_papers)} papers")
    
    # 2. PDFå¤‰æ›
    print("ğŸ”„ Starting PDF conversion...")
    pdf_dir = Path("consciousness_research_2025/pdfs")
    
    if pdf_dir.exists() and list(pdf_dir.glob("*.pdf")):
        converter = PDFToMarkdownConverter(
            str(pdf_dir), 
            str(pdf_dir.parent / "markdown")
        )
        
        results = converter.convert_all_pdfs()
        summary = converter.get_conversion_summary()
        
        print(f"âœ… Conversion complete:")
        print(f"   Success rate: {summary['success_rate']:.1f}%")
        print(f"   Total pages: {summary['total_pages_converted']}")
    
    # 3. ç ”ç©¶ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
    generate_research_notes(all_papers, summary)

def generate_research_notes(papers, conversion_summary):
    """ç ”ç©¶ãƒãƒ¼ãƒˆã®è‡ªå‹•ç”Ÿæˆ"""
    notes = f"""# æ„è­˜ç ”ç©¶è«–æ–‡ãƒ¬ãƒ“ãƒ¥ãƒ¼ {time.strftime('%Y-%m-%d')}

## åé›†ã‚µãƒãƒªãƒ¼
- è«–æ–‡æ•°: {len(papers)}
- å¤‰æ›æˆåŠŸç‡: {conversion_summary.get('success_rate', 0):.1f}%
- ç·ãƒšãƒ¼ã‚¸æ•°: {conversion_summary.get('total_pages_converted', 0)}

## ä¸»è¦è«–æ–‡
"""
    
    for i, paper in enumerate(papers[:5], 1):
        notes += f"\n### {i}. {paper['title']}\n"
        notes += f"**è‘—è€…:** {', '.join(paper.get('authors', []))}\n"
        notes += f"**æ¦‚è¦:** {paper['abstract'][:200]}...\n"
    
    with open("research_notes.md", "w", encoding="utf-8") as f:
        f.write(notes)
    
    print("ğŸ“ Research notes generated: research_notes.md")

if __name__ == "__main__":
    automated_research_pipeline()
```

## ğŸ“Š å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹é€ ã¨æ´»ç”¨

### ç”Ÿæˆã•ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ 

```
institute/library/
â”œâ”€â”€ author_search/
â”‚   â””â”€â”€ Ramstead/
â”‚       â”œâ”€â”€ pdfs/                    # å…ƒã®PDFãƒ•ã‚¡ã‚¤ãƒ«
â”‚       â”‚   â”œâ”€â”€ paper_1.pdf
â”‚       â”‚   â””â”€â”€ paper_2.pdf
â”‚       â”œâ”€â”€ markdown/                # å¤‰æ›ã•ã‚ŒãŸãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³
â”‚       â”‚   â”œâ”€â”€ paper_1.md
â”‚       â”‚   â””â”€â”€ paper_2.md
â”‚       â”œâ”€â”€ metadata/                # è«–æ–‡ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
â”‚       â”‚   â”œâ”€â”€ paper_1.json
â”‚       â”‚   â””â”€â”€ paper_2.json
â”‚       â”œâ”€â”€ search_summary.json      # æ¤œç´¢çµæœã‚µãƒãƒªãƒ¼
â”‚       â””â”€â”€ conversion_log.json      # å¤‰æ›ãƒ­ã‚°
â””â”€â”€ batch_conversion_results.json    # ä¸€æ‹¬å¤‰æ›çµæœ
```

### ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¾‹

```markdown
---
title: Neural and phenotypic representation under the free-energy principle
author: MJD Ramstead, C Hesp, A Tschantz
pages: 25
conversion_method: pymupdf4llm
converted_at: 2025-07-30T19:55:52.326089
---

# Neural and phenotypic representation under the free-energy principle

## Abstract

The aim of this paper is to leverage the free-energy principle 
and its corollary process theory, active inference, to develop 
a generic, generalizable model of the representational capacities...

## 1. Introduction

Recent advances in theoretical neuroscience have provided 
formal frameworks for understanding how biological systems...

### 1.1 The Free Energy Principle

The free energy principle (FEP) provides a normative framework...

## 2. Methods

### 2.1 Mathematical Framework

The mathematical framework underlying active inference...

$$F = \mathbb{E}_{q}[\ln q(x) - \ln p(x,y)]$$

## 3. Results

Our analysis reveals three key findings...

## References

1. Friston, K. (2010). The free-energy principle: a unified brain theory?
2. Ramstead, M. J. D., et al. (2020). A tale of two densities...
```

## ğŸ¯ ç‰¹å®šç”¨é€”ã®ä½¿ç”¨ä¾‹

### ç ”ç©¶ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç”¨ã®è«–æ–‡åé›†

```bash
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: "æ„è­˜ã®ãƒãƒ¼ãƒ‰ãƒ—ãƒ­ãƒ–ãƒ¬ãƒ "
mkdir -p /institute/projects/hard_problem_of_consciousness

# é–¢é€£è«–æ–‡ã‚’åé›†
python -c "
from paper_collector import PaperCollector
collector = PaperCollector('/institute/projects/hard_problem_of_consciousness')

# Chalmersã®è«–æ–‡
chalmers_papers = collector.search_arxiv('au:\"David Chalmers\"', 20)

# ãƒãƒ¼ãƒ‰ãƒ—ãƒ­ãƒ–ãƒ¬ãƒ é–¢é€£
hard_problem_papers = collector.search_arxiv('all:\"hard problem consciousness\"', 30)

print(f'Chalmers: {len(chalmers_papers)} papers')
print(f'Hard Problem: {len(hard_problem_papers)} papers')
"
```

### å­¦ä¼šç™ºè¡¨æº–å‚™ç”¨ã®è«–æ–‡èª¿æŸ»

```bash
# å­¦ä¼š: "Consciousness and Artificial Intelligence"
mkdir -p /institute/conferences/consciousness_ai_2025

# AIæ„è­˜ç ”ç©¶ã®æœ€æ–°è«–æ–‡
python -c "
from paper_collector import PaperCollector
collector = PaperCollector('/institute/conferences/consciousness_ai_2025')

recent_papers = collector.search_arxiv(
    'all:\"artificial consciousness\" OR all:\"machine consciousness\"', 
    50
)

# 2024å¹´ä»¥é™ã®è«–æ–‡ã«çµã‚Šè¾¼ã¿
recent_papers_2024 = [p for p in recent_papers if '2024' in p.get('published', '')]
print(f'Recent AI consciousness papers: {len(recent_papers_2024)}')
"

# ã™ã¹ã¦ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã«å¤‰æ›
python batch_convert.py --directory "/institute/conferences/consciousness_ai_2025/pdfs"
```

### ç ”ç©¶è€…åˆ¥ã®è«–æ–‡ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ä½œæˆ

```bash
# ä¸»è¦ç ”ç©¶è€…ã®è«–æ–‡ã‚’åé›†
researchers=("Karl Friston" "Andy Clark" "Anil Seth" "Christof Koch" "Giulio Tononi")

for researcher in "${researchers[@]}"; do
    echo "Collecting papers for: $researcher"
    python -c "
from paper_collector import PaperCollector
import time

researcher = '$researcher'
collector = PaperCollector(f'/institute/researchers/{researcher.replace(\" \", \"_\")}')

# è‘—è€…åæ¤œç´¢
papers = collector.search_arxiv(f'au:\"{researcher}\"', 30)
time.sleep(2)

# Google Scholarã§ã‚‚æ¤œç´¢
scholar_papers = collector.search_google_scholar(f'\"{researcher}\" consciousness', 10)

print(f'{researcher}: {len(papers)} arXiv + {len(scholar_papers)} Scholar papers')
"
done

# ã™ã¹ã¦ã‚’ä¸€æ‹¬å¤‰æ›
python batch_convert.py
```

## ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºæ–¹æ³•

#### 1. PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå¤±æ•—ã™ã‚‹å ´åˆ

```bash
# ãƒ­ã‚°ã‚’ç¢ºèª
tail -f /institute/library/*/conversion_log.json

# æ‰‹å‹•ã§PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦é…ç½®
wget "https://arxiv.org/pdf/2301.11816.pdf" -O /path/to/pdfs/paper.pdf
```

#### 2. å¤‰æ›ãŒå¤±æ•—ã™ã‚‹å ´åˆ

```bash
# å¤‰æ›ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’å†ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install --upgrade pymupdf4llm PyMuPDF

# å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒ†ã‚¹ãƒˆ
python pdf_to_markdown.py /path/to/pdfs --single_file problem_paper.pdf
```

#### 3. Google ScholarãŒãƒ–ãƒ­ãƒƒã‚¯ã™ã‚‹å ´åˆ

```python
# ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–“éš”ã‚’å¢—ã‚„ã™
import time
time.sleep(5)  # 5ç§’é–“éš”ã«å¤‰æ›´

# arXivã®ã¿ã‚’ä½¿ç”¨
collector = PaperCollector("papers")
papers = collector.search_arxiv("consciousness", 50)
```

## ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### å¤§é‡è«–æ–‡ã®åŠ¹ç‡çš„ãªå‡¦ç†

```bash
# ä¸¦åˆ—å‡¦ç†ã§é«˜é€ŸåŒ–ï¼ˆæ³¨æ„: APIåˆ¶é™ã«æ³¨æ„ï¼‰
python -c "
import concurrent.futures
from paper_collector import PaperCollector

def process_keyword(keyword):
    collector = PaperCollector(f'batch_{keyword.replace(\" \", \"_\")}')
    return collector.search_arxiv(keyword, 20)

keywords = ['consciousness', 'qualia', 'phenomenology', 'IIT']

with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
    results = executor.map(process_keyword, keywords)
    
for result in results:
    print(f'Found {len(result)} papers')
"
```

## ğŸ“ Claude Code Plan Modeã§ã®æ´»ç”¨

### Plan Modeã§ã®ä½¿ç”¨ä¾‹

```bash
# Claude Code plan modeã‹ã‚‰å®Ÿè¡Œ
claude-code --plan

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹:
# "Ramsteadã®è‡ªç”±ã‚¨ãƒãƒ«ã‚®ãƒ¼åŸç†ã«é–¢ã™ã‚‹è«–æ–‡ã‚’åé›†ã—ã¦ã€
#  ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã«å¤‰æ›ã—ã€ä¸»è¦ãªã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„"

# å®Ÿéš›ã®ã‚³ãƒãƒ³ãƒ‰ï¼ˆplan modeå†…ã§å®Ÿè¡Œï¼‰
python batch_convert.py --author "Ramstead"
```

ã“ã®ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦ã€åŠ¹ç‡çš„ãªæ„è­˜ç ”ç©¶è«–æ–‡ã®åé›†ãƒ»æ´»ç”¨ã‚’è¡Œã£ã¦ãã ã•ã„ï¼