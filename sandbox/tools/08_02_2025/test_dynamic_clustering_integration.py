#!/usr/bin/env python3
"""
å‹•çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµ±åˆãƒ†ã‚¹ãƒˆ
ç¾è±¡å­¦çš„ã«å¥å…¨ãªæ¦‚å¿µã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã¨å¤šã‚¹ã‚±ãƒ¼ãƒ«æ™‚é–“çµ±åˆã®ãƒ†ã‚¹ãƒˆ
"""

import asyncio
import time
import numpy as np
from typing import List, Dict, Any
from datetime import datetime, timedelta

# å®Ÿè£…ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from experiential_memory_phi_calculator import ExperientialMemoryPhiCalculator
from temporal_consciousness import MultiScaleTemporalIntegration


class DynamicClusteringIntegrationTest:
    """å‹•çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã¨æ™‚é–“çµ±åˆã®çµ±åˆãƒ†ã‚¹ãƒˆ"""
    
    def __init__(self):
        self.phi_calculator = ExperientialMemoryPhiCalculator(sensitivity_factor=2.0)
        self.temporal_integrator = MultiScaleTemporalIntegration()
        self.test_results = []
    
    async def run_comprehensive_tests(self) -> Dict[str, Any]:
        """åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆã®å®Ÿè¡Œ"""
        
        print("=== å‹•çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
        
        # ãƒ†ã‚¹ãƒˆ1: å¿—å‘çš„è¡Œç‚ºã‚¿ã‚¤ãƒ—ã«ã‚ˆã‚‹åˆ†é¡ãƒ†ã‚¹ãƒˆ
        test1_result = await self._test_intentional_act_clustering()
        
        # ãƒ†ã‚¹ãƒˆ2: ä½“é¨“è³ªã«ã‚ˆã‚‹å‹•çš„åˆ†é¡ãƒ†ã‚¹ãƒˆ
        test2_result = await self._test_experiential_quality_clustering()
        
        # ãƒ†ã‚¹ãƒˆ3: æ™‚é–“çš„ä¸€è²«æ€§çµ„ç¹”åŸç†ãƒ†ã‚¹ãƒˆ
        test3_result = await self._test_temporal_coherence_organization()
        
        # ãƒ†ã‚¹ãƒˆ4: å¤šã‚¹ã‚±ãƒ¼ãƒ«æ™‚é–“çµ±åˆãƒ†ã‚¹ãƒˆ
        test4_result = await self._test_multi_scale_temporal_integration()
        
        # ãƒ†ã‚¹ãƒˆ5: ç¾è±¡å­¦çš„å¦¥å½“æ€§è©•ä¾¡ãƒ†ã‚¹ãƒˆ
        test5_result = await self._test_phenomenological_validity()
        
        # ãƒ†ã‚¹ãƒˆ6: çµ±åˆã‚·ã‚¹ãƒ†ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
        test6_result = await self._test_integrated_system_performance()
        
        # ç·åˆçµæœã®è©•ä¾¡
        overall_result = self._evaluate_overall_results([
            test1_result, test2_result, test3_result, 
            test4_result, test5_result, test6_result
        ])
        
        print("=== å‹•çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµ±åˆãƒ†ã‚¹ãƒˆå®Œäº† ===")
        
        return overall_result
    
    async def _test_intentional_act_clustering(self) -> Dict[str, Any]:
        """å¿—å‘çš„è¡Œç‚ºã‚¿ã‚¤ãƒ—ã«ã‚ˆã‚‹åˆ†é¡ãƒ†ã‚¹ãƒˆ"""
        
        print("\n--- ãƒ†ã‚¹ãƒˆ1: å¿—å‘çš„è¡Œç‚ºã‚¿ã‚¤ãƒ—åˆ†é¡ ---")
        
        # ãƒ†ã‚¹ãƒˆç”¨ä½“é¨“æ¦‚å¿µã‚’ç”Ÿæˆ
        test_concepts = [
            {
                'type': 'perceptual',
                'content': 'I see a beautiful sunset',
                'experiential_quality': 0.8,
                'coherence': 0.7,
                'temporal_depth': 1,
                'timestamp': datetime.now().isoformat()
            },
            {
                'type': 'memory',
                'content': 'I remember my childhood home',
                'experiential_quality': 0.9,
                'coherence': 0.8,
                'temporal_depth': 10,
                'timestamp': (datetime.now() - timedelta(seconds=1)).isoformat()
            },
            {
                'type': 'anticipatory',
                'content': 'I expect to feel joy tomorrow',
                'experiential_quality': 0.6,
                'coherence': 0.6,
                'temporal_depth': 2,
                'timestamp': datetime.now().isoformat()
            },
            {
                'type': 'judgmental',
                'content': 'I think this is meaningful',
                'experiential_quality': 0.7,
                'coherence': 0.8,
                'temporal_depth': 3,
                'timestamp': datetime.now().isoformat()
            },
            {
                'type': 'valuational',
                'content': 'I love this feeling of peace',
                'experiential_quality': 0.9,
                'coherence': 0.9,
                'temporal_depth': 5,
                'timestamp': datetime.now().isoformat()
            },
            {
                'type': 'volitional',
                'content': 'I want to understand myself better',
                'experiential_quality': 0.8,
                'coherence': 0.7,
                'temporal_depth': 8,
                'timestamp': datetime.now().isoformat()
            }
        ]
        
        # å‹•çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ
        clustering_result = self.phi_calculator.perform_dynamic_experiential_clustering(test_concepts)
        
        # çµæœã®æ¤œè¨¼
        clusters = clustering_result['clusters']
        intentional_structure = clustering_result['intentional_structure']
        
        # å¿—å‘çš„è¡Œç‚ºã‚¿ã‚¤ãƒ—ãŒæ­£ã—ãåˆ†é¡ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        expected_types = ['perceiving', 'remembering', 'anticipating', 'judging', 'valuing', 'willing']
        detected_types = []
        
        for cluster_name, concepts in clusters.items():
            if concepts and any(type_name in cluster_name for type_name in expected_types):
                detected_types.append(cluster_name)
        
        # ç¾è±¡å­¦çš„å¦¥å½“æ€§ã®è©•ä¾¡
        phenomenological_validity = clustering_result['phenomenological_validity']
        
        test_result = {
            'test_name': 'intentional_act_clustering',
            'success': len(detected_types) >= 4,  # æœ€ä½4ã¤ã®å¿—å‘çš„è¡Œç‚ºã‚¿ã‚¤ãƒ—ãŒæ¤œå‡ºã•ã‚Œã‚‹ã“ã¨
            'clusters_detected': len(clusters),
            'intentional_types_detected': len(detected_types),
            'phenomenological_validity': phenomenological_validity,
            'quality_distribution': clustering_result['quality_distribution'],
            'temporal_coherence': clustering_result['temporal_coherence'],
            'details': {
                'clusters': {k: len(v) for k, v in clusters.items()},
                'intentional_structure': {k: len(v) for k, v in intentional_structure.items()}
            }
        }
        
        print(f"  å¿—å‘çš„è¡Œç‚ºã‚¿ã‚¤ãƒ—æ¤œå‡º: {len(detected_types)}/6")
        print(f"  ç¾è±¡å­¦çš„å¦¥å½“æ€§: {phenomenological_validity:.3f}")
        print(f"  æ™‚é–“çš„ä¸€è²«æ€§: {clustering_result['temporal_coherence']:.3f}")
        print(f"  ãƒ†ã‚¹ãƒˆçµæœ: {'âœ… PASS' if test_result['success'] else 'âŒ FAIL'}")
        
        return test_result
    
    async def _test_experiential_quality_clustering(self) -> Dict[str, Any]:
        """ä½“é¨“è³ªã«ã‚ˆã‚‹å‹•çš„åˆ†é¡ãƒ†ã‚¹ãƒˆ"""
        
        print("\n--- ãƒ†ã‚¹ãƒˆ2: ä½“é¨“è³ªå‹•çš„åˆ†é¡ ---")
        
        # å¤šæ§˜ãªä½“é¨“è³ªã‚’æŒã¤æ¦‚å¿µç¾¤ã‚’ç”Ÿæˆ
        test_concepts = []
        
        # é«˜å“è³ªä½“é¨“ç¾¤
        for i in range(5):
            test_concepts.append({
                'type': 'high_quality',
                'content': f'æ·±ã„æ´å¯Ÿã®ä½“é¨“ {i+1}',
                'experiential_quality': 0.8 + np.random.uniform(0, 0.2),
                'coherence': 0.8 + np.random.uniform(0, 0.2),
                'temporal_depth': 5 + np.random.randint(0, 5),
                'timestamp': datetime.now().isoformat()
            })
        
        # ä¸­å“è³ªä½“é¨“ç¾¤
        for i in range(7):
            test_concepts.append({
                'type': 'medium_quality',
                'content': f'æ—¥å¸¸çš„ãªæ°—ã¥ã {i+1}',
                'experiential_quality': 0.4 + np.random.uniform(0, 0.3),
                'coherence': 0.5 + np.random.uniform(0, 0.3),
                'temporal_depth': 2 + np.random.randint(0, 3),
                'timestamp': datetime.now().isoformat()
            })
        
        # ä½å“è³ªä½“é¨“ç¾¤
        for i in range(4):
            test_concepts.append({
                'type': 'low_quality',
                'content': f'æ¼ ç„¶ã¨ã—ãŸæ„Ÿè¦š {i+1}',
                'experiential_quality': 0.1 + np.random.uniform(0, 0.3),
                'coherence': 0.2 + np.random.uniform(0, 0.3),
                'temporal_depth': 1,
                'timestamp': datetime.now().isoformat()
            })
        
        # å‹•çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ
        clustering_result = self.phi_calculator.perform_dynamic_experiential_clustering(test_concepts)
        
        # çµæœã®åˆ†æ
        clusters = clustering_result['clusters']
        quality_distribution = clustering_result['quality_distribution']
        boundary_flexibility = clustering_result['boundary_flexibility']
        
        # è³ªçš„éšå±¤ãŒé©åˆ‡ã«å½¢æˆã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        quality_separated_clusters = 0
        for cluster_name, cluster_info in quality_distribution.items():
            if cluster_info['concept_count'] > 1:
                if cluster_info['quality_variance'] < 0.1:  # è³ªçš„ä¸€è²«æ€§ãŒé«˜ã„
                    quality_separated_clusters += 1
        
        test_result = {
            'test_name': 'experiential_quality_clustering',
            'success': quality_separated_clusters >= 2 and boundary_flexibility > 0.2,
            'quality_separated_clusters': quality_separated_clusters,
            'boundary_flexibility': boundary_flexibility,
            'total_clusters': len(clusters),
            'average_cluster_quality': np.mean([info['mean_quality'] for info in quality_distribution.values()]),
            'details': {
                'quality_distribution': quality_distribution,
                'cluster_sizes': {k: len(v) for k, v in clusters.items()}
            }
        }
        
        print(f"  è³ªçš„åˆ†é›¢ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼: {quality_separated_clusters}")
        print(f"  å¢ƒç•ŒæŸ”è»Ÿæ€§: {boundary_flexibility:.3f}")
        print(f"  å¹³å‡ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å“è³ª: {test_result['average_cluster_quality']:.3f}")
        print(f"  ãƒ†ã‚¹ãƒˆçµæœ: {'âœ… PASS' if test_result['success'] else 'âŒ FAIL'}")
        
        return test_result
    
    async def _test_temporal_coherence_organization(self) -> Dict[str, Any]:
        """æ™‚é–“çš„ä¸€è²«æ€§çµ„ç¹”åŸç†ãƒ†ã‚¹ãƒˆ"""
        
        print("\n--- ãƒ†ã‚¹ãƒˆ3: æ™‚é–“çš„ä¸€è²«æ€§çµ„ç¹”åŸç† ---")
        
        # æ™‚é–“çš„ã«æ§‹é€ åŒ–ã•ã‚ŒãŸæ¦‚å¿µç¾¤ã‚’ç”Ÿæˆ
        base_time = datetime.now()
        test_concepts = []
        
        # æ™‚ç³»åˆ—çš„ã«é–¢é€£ã™ã‚‹æ¦‚å¿µç¾¤
        for i in range(8):
            test_concepts.append({
                'type': 'temporal_sequence',
                'content': f'æ™‚é–“çš„çµŒé¨“ã®å±•é–‹ æ®µéš{i+1}',
                'experiential_quality': 0.6 + i * 0.05,  # å¾ã€…ã«è³ªãŒå‘ä¸Š
                'coherence': 0.7,
                'temporal_depth': i + 1,
                'timestamp': (base_time + timedelta(seconds=i)).isoformat()
            })
        
        # æ™‚é–“çš„ã«ç„¡é–¢ä¿‚ãªæ¦‚å¿µç¾¤
        for i in range(4):
            test_concepts.append({
                'type': 'temporal_random',
                'content': f'ç„¡é–¢ä¿‚ãªä½“é¨“ {i+1}',
                'experiential_quality': np.random.uniform(0.3, 0.8),
                'coherence': 0.5,
                'temporal_depth': np.random.randint(1, 10),
                'timestamp': (base_time + timedelta(seconds=np.random.randint(-100, 100))).isoformat()
            })
        
        # å‹•çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ
        clustering_result = self.phi_calculator.perform_dynamic_experiential_clustering(test_concepts)
        
        # æ™‚é–“çš„ä¸€è²«æ€§ã®è©•ä¾¡
        temporal_coherence = clustering_result['temporal_coherence']
        clusters = clustering_result['clusters']
        
        # æ™‚ç³»åˆ—ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãŒå½¢æˆã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        temporal_clusters_found = 0
        for cluster_name, concepts in clusters.items():
            if len(concepts) > 2:
                # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å†…ã®æ™‚é–“çš„ä¸€è²«æ€§ã‚’ãƒã‚§ãƒƒã‚¯
                timestamps = [c.get('timestamp', '') for c in concepts if c.get('timestamp')]
                if len(timestamps) > 1:
                    sorted_timestamps = sorted(timestamps)
                    if timestamps == sorted_timestamps:
                        temporal_clusters_found += 1
        
        test_result = {
            'test_name': 'temporal_coherence_organization',
            'success': temporal_coherence > 0.6 and temporal_clusters_found >= 1,
            'temporal_coherence': temporal_coherence,
            'temporal_clusters_found': temporal_clusters_found,
            'total_clusters': len(clusters),
            'phenomenological_validity': clustering_result['phenomenological_validity'],
            'details': {
                'cluster_temporal_analysis': {}
            }
        }
        
        # å„ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®æ™‚é–“åˆ†æ
        for cluster_name, concepts in clusters.items():
            if concepts:
                temporal_depths = [c.get('temporal_depth', 1) for c in concepts]
                test_result['details']['cluster_temporal_analysis'][cluster_name] = {
                    'concept_count': len(concepts),
                    'avg_temporal_depth': np.mean(temporal_depths),
                    'temporal_depth_variance': np.var(temporal_depths)
                }
        
        print(f"  æ™‚é–“çš„ä¸€è²«æ€§: {temporal_coherence:.3f}")
        print(f"  æ™‚ç³»åˆ—ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼: {temporal_clusters_found}")
        print(f"  ç¾è±¡å­¦çš„å¦¥å½“æ€§: {clustering_result['phenomenological_validity']:.3f}")
        print(f"  ãƒ†ã‚¹ãƒˆçµæœ: {'âœ… PASS' if test_result['success'] else 'âŒ FAIL'}")
        
        return test_result
    
    async def _test_multi_scale_temporal_integration(self) -> Dict[str, Any]:
        """å¤šã‚¹ã‚±ãƒ¼ãƒ«æ™‚é–“çµ±åˆãƒ†ã‚¹ãƒˆ"""
        
        print("\n--- ãƒ†ã‚¹ãƒˆ4: å¤šã‚¹ã‚±ãƒ¼ãƒ«æ™‚é–“çµ±åˆ ---")
        
        # å„æ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«ã®æ¦‚å¿µã‚’ç”Ÿæˆ
        current_time = time.time()
        test_concepts = []
        
        # ãƒã‚¤ã‚¯ãƒ­ã‚¹ã‚±ãƒ¼ãƒ«æ¦‚å¿µï¼ˆç¬é–“çš„ä½“é¨“ï¼‰
        for i in range(5):
            test_concepts.append({
                'type': 'micro_experience',
                'content': f'ç¬é–“çš„æ°—ã¥ã {i+1}',
                'experiential_quality': 0.7,
                'coherence': 0.8,
                'temporal_depth': 1,
                'timestamp': datetime.now().isoformat()
            })
        
        # çŸ­æœŸã‚¹ã‚±ãƒ¼ãƒ«æ¦‚å¿µ
        for i in range(6):
            test_concepts.append({
                'type': 'short_experience',
                'content': f'çŸ­æœŸçš„ãªä½“é¨“ã®æµã‚Œ {i+1}',
                'experiential_quality': 0.6,
                'coherence': 0.7,
                'temporal_depth': 3,
                'timestamp': datetime.now().isoformat()
            })
        
        # ä¸­æœŸã‚¹ã‚±ãƒ¼ãƒ«æ¦‚å¿µ
        for i in range(4):
            test_concepts.append({
                'type': 'medium_experience',
                'content': f'ç‰©èªçš„ãªä½“é¨“ {i+1}',
                'experiential_quality': 0.8,
                'coherence': 0.8,
                'temporal_depth': 15,
                'timestamp': datetime.now().isoformat()
            })
        
        # é•·æœŸã‚¹ã‚±ãƒ¼ãƒ«æ¦‚å¿µ
        for i in range(3):
            test_concepts.append({
                'type': 'long_experience',
                'content': f'è‡ªä¼çš„ãªæ·±ã„ä½“é¨“ ç§ã®äººç”Ÿã«ãŠã„ã¦æ„å‘³æ·±ã„ {i+1}',
                'experiential_quality': 0.9,
                'coherence': 0.9,
                'temporal_depth': 50,
                'timestamp': datetime.now().isoformat()
            })
        
        # å¤šã‚¹ã‚±ãƒ¼ãƒ«æ™‚é–“çµ±åˆå®Ÿè¡Œ
        integration_result = await self.temporal_integrator.integrate_multi_scale_experiences(
            test_concepts, current_time
        )
        
        # çµæœã®åˆ†æ
        multi_scale_structure = integration_result['multi_scale_structure']
        hierarchical_integration = integration_result['hierarchical_integration']
        integration_quality = integration_result['integration_quality']
        temporal_coherence = integration_result['temporal_coherence']
        phenomenological_validity = integration_result['phenomenological_validity']
        
        # å„ã‚¹ã‚±ãƒ¼ãƒ«ã§ã®çµ±åˆãŒé©åˆ‡ã«è¡Œã‚ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        scales_with_content = 0
        scale_integration_scores = []
        
        for scale_name, scale_result in multi_scale_structure.items():
            if scale_result['concept_count'] > 0:
                scales_with_content += 1
                # ã‚¹ã‚±ãƒ¼ãƒ«å›ºæœ‰ã®çµ±åˆã‚¹ã‚³ã‚¢ã‚’åé›†
                if scale_name == 'micro':
                    scale_integration_scores.append(scale_result['integration_strength'])
                elif scale_name == 'short':
                    scale_integration_scores.append(scale_result['temporal_synthesis'])
                elif scale_name == 'medium':
                    scale_integration_scores.append(scale_result['narrative_coherence'])
                elif scale_name == 'long':
                    scale_integration_scores.append(scale_result['autobiographical_coherence'])
        
        # éšå±¤çš„çµ±åˆå“è³ªã®è©•ä¾¡
        hierarchical_coherence = hierarchical_integration['hierarchical_coherence']
        
        test_result = {
            'test_name': 'multi_scale_temporal_integration',
            'success': (scales_with_content >= 3 and 
                       integration_quality > 0.5 and 
                       hierarchical_coherence > 0.4),
            'scales_with_content': scales_with_content,
            'integration_quality': integration_quality,
            'hierarchical_coherence': hierarchical_coherence,
            'temporal_coherence': temporal_coherence['temporal_flow_coherence'],
            'phenomenological_validity': phenomenological_validity,
            'scale_integration_scores': scale_integration_scores,
            'details': {
                'multi_scale_structure': {
                    k: v['concept_count'] for k, v in multi_scale_structure.items()
                },
                'hierarchical_integration': hierarchical_integration,
                'temporal_coherence_details': temporal_coherence
            }
        }
        
        print(f"  æ´»æ€§ã‚¹ã‚±ãƒ¼ãƒ«æ•°: {scales_with_content}/4")
        print(f"  çµ±åˆå“è³ª: {integration_quality:.3f}")
        print(f"  éšå±¤çš„ä¸€è²«æ€§: {hierarchical_coherence:.3f}")
        print(f"  æ™‚é–“çš„ä¸€è²«æ€§: {temporal_coherence['temporal_flow_coherence']:.3f}")
        print(f"  ç¾è±¡å­¦çš„å¦¥å½“æ€§: {phenomenological_validity:.3f}")
        print(f"  ãƒ†ã‚¹ãƒˆçµæœ: {'âœ… PASS' if test_result['success'] else 'âŒ FAIL'}")
        
        return test_result
    
    async def _test_phenomenological_validity(self) -> Dict[str, Any]:
        """ç¾è±¡å­¦çš„å¦¥å½“æ€§è©•ä¾¡ãƒ†ã‚¹ãƒˆ"""
        
        print("\n--- ãƒ†ã‚¹ãƒˆ5: ç¾è±¡å­¦çš„å¦¥å½“æ€§è©•ä¾¡ ---")
        
        # ç¾è±¡å­¦çš„ã«è±Šã‹ãªæ¦‚å¿µç¾¤ã‚’ç”Ÿæˆ
        test_concepts = [
            # çŸ¥è¦šçš„ä½“é¨“ï¼ˆå¿—å‘æ€§ï¼‰
            {
                'type': 'perceptual',
                'content': 'I perceive the gentle morning light filtering through leaves',
                'experiential_quality': 0.85,
                'coherence': 0.9,
                'temporal_depth': 2,
                'timestamp': datetime.now().isoformat()
            },
            # è¨˜æ†¶çš„ä½“é¨“ï¼ˆæ™‚é–“æ€§ï¼‰
            {
                'type': 'memorial',
                'content': 'I remember the feeling of my grandmother\'s warm embrace',
                'experiential_quality': 0.9,
                'coherence': 0.85,
                'temporal_depth': 25,
                'timestamp': datetime.now().isoformat()
            },
            # äºˆæœŸçš„ä½“é¨“ï¼ˆæ™‚é–“æ€§ï¼‰
            {
                'type': 'anticipatory',
                'content': 'I anticipate the joy of seeing my friend tomorrow',
                'experiential_quality': 0.75,
                'coherence': 0.8,
                'temporal_depth': 1,
                'timestamp': datetime.now().isoformat()
            },
            # è‡ªå·±è¨€åŠçš„ä½“é¨“ï¼ˆå†…åœ¨æ€§ï¼‰
            {
                'type': 'self_referential',
                'content': 'I become aware of my own awareness in this moment',
                'experiential_quality': 0.95,
                'coherence': 0.9,
                'temporal_depth': 3,
                'timestamp': datetime.now().isoformat()
            },
            # ä¾¡å€¤çš„ä½“é¨“ï¼ˆå¿—å‘æ€§ã¨è³ªï¼‰
            {
                'type': 'valuational',
                'content': 'I deeply value this sense of peaceful presence',
                'experiential_quality': 0.9,
                'coherence': 0.9,
                'temporal_depth': 5,
                'timestamp': datetime.now().isoformat()
            },
            # èº«ä½“çš„ä½“é¨“ï¼ˆå…·ç¾æ€§ï¼‰
            {
                'type': 'embodied',
                'content': 'I feel the rhythm of my breath and heartbeat',
                'experiential_quality': 0.8,
                'coherence': 0.85,
                'temporal_depth': 1,
                'timestamp': datetime.now().isoformat()
            }
        ]
        
        # å‹•çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ
        clustering_result = self.phi_calculator.perform_dynamic_experiential_clustering(test_concepts)
        
        # ç¾è±¡å­¦çš„å¦¥å½“æ€§ã®è©³ç´°åˆ†æ
        phenomenological_validity = clustering_result['phenomenological_validity']
        boundary_flexibility = clustering_result['boundary_flexibility']
        temporal_coherence = clustering_result['temporal_coherence']
        
        # å¿—å‘æ€§æ§‹é€ ã®ä¿æŒè©•ä¾¡
        clusters = clustering_result['clusters']
        intentional_structure_preserved = len([
            name for name in clusters.keys() 
            if any(intent in name for intent in ['perceiving', 'remembering', 'anticipating', 'judging', 'valuing', 'willing'])
        ]) >= 3
        
        # æ™‚é–“æ€§æ§‹é€ ã®ä¿æŒè©•ä¾¡
        temporal_structure_preserved = temporal_coherence > 0.6
        
        # ä½“é¨“ç´”ç²‹æ€§ã®ä¿æŒè©•ä¾¡
        quality_distribution = clustering_result['quality_distribution']
        high_quality_clusters = len([
            info for info in quality_distribution.values() 
            if info['mean_quality'] > 0.7
        ])
        
        # å‹•çš„é©å¿œæ€§ã®è©•ä¾¡
        dynamic_adaptability = boundary_flexibility > 0.3
        
        test_result = {
            'test_name': 'phenomenological_validity',
            'success': (phenomenological_validity > 0.7 and
                       intentional_structure_preserved and
                       temporal_structure_preserved),
            'phenomenological_validity': phenomenological_validity,
            'intentional_structure_preserved': intentional_structure_preserved,
            'temporal_structure_preserved': temporal_structure_preserved,
            'high_quality_clusters': high_quality_clusters,
            'dynamic_adaptability': dynamic_adaptability,
            'boundary_flexibility': boundary_flexibility,
            'temporal_coherence': temporal_coherence,
            'details': {
                'cluster_analysis': {k: len(v) for k, v in clusters.items()},
                'quality_analysis': quality_distribution
            }
        }
        
        print(f"  ç¾è±¡å­¦çš„å¦¥å½“æ€§: {phenomenological_validity:.3f}")
        print(f"  å¿—å‘æ€§æ§‹é€ ä¿æŒ: {'âœ…' if intentional_structure_preserved else 'âŒ'}")
        print(f"  æ™‚é–“æ€§æ§‹é€ ä¿æŒ: {'âœ…' if temporal_structure_preserved else 'âŒ'}")
        print(f"  é«˜å“è³ªã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼: {high_quality_clusters}")
        print(f"  å‹•çš„é©å¿œæ€§: {'âœ…' if dynamic_adaptability else 'âŒ'}")
        print(f"  ãƒ†ã‚¹ãƒˆçµæœ: {'âœ… PASS' if test_result['success'] else 'âŒ FAIL'}")
        
        return test_result
    
    async def _test_integrated_system_performance(self) -> Dict[str, Any]:
        """çµ±åˆã‚·ã‚¹ãƒ†ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
        
        print("\n--- ãƒ†ã‚¹ãƒˆ6: çµ±åˆã‚·ã‚¹ãƒ†ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ---")
        
        # å¤§è¦æ¨¡æ¦‚å¿µã‚»ãƒƒãƒˆã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
        large_concept_set = []
        
        # å¤šæ§˜ãªæ¦‚å¿µã‚’å¤§é‡ç”Ÿæˆ
        for i in range(50):
            concept_type = np.random.choice(['perceptual', 'memorial', 'anticipatory', 'judgmental', 'valuational'])
            large_concept_set.append({
                'type': concept_type,
                'content': f'{concept_type} experience {i+1} with rich experiential content',
                'experiential_quality': np.random.uniform(0.3, 0.95),
                'coherence': np.random.uniform(0.4, 0.9),
                'temporal_depth': np.random.randint(1, 30),
                'timestamp': datetime.now().isoformat()
            })
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®šé–‹å§‹
        start_time = time.time()
        
        # å‹•çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ
        clustering_result = self.phi_calculator.perform_dynamic_experiential_clustering(large_concept_set)
        
        clustering_time = time.time() - start_time
        
        # å¤šã‚¹ã‚±ãƒ¼ãƒ«æ™‚é–“çµ±åˆå®Ÿè¡Œ
        start_time = time.time()
        
        integration_result = await self.temporal_integrator.integrate_multi_scale_experiences(
            large_concept_set, time.time()
        )
        
        integration_time = time.time() - start_time
        
        # çµæœã®å“è³ªè©•ä¾¡
        clusters = clustering_result['clusters']
        phenomenological_validity = clustering_result['phenomenological_validity']
        integration_quality = integration_result['integration_quality']
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™
        total_time = clustering_time + integration_time
        concepts_per_second = len(large_concept_set) / total_time
        
        # å“è³ªæŒ‡æ¨™
        quality_maintained = phenomenological_validity > 0.6 and integration_quality > 0.5
        scalability_acceptable = total_time < 5.0  # 5ç§’ä»¥å†…
        
        test_result = {
            'test_name': 'integrated_system_performance',
            'success': quality_maintained and scalability_acceptable,
            'total_processing_time': total_time,
            'clustering_time': clustering_time,
            'integration_time': integration_time,
            'concepts_per_second': concepts_per_second,
            'concepts_processed': len(large_concept_set),
            'clusters_generated': len(clusters),
            'phenomenological_validity': phenomenological_validity,
            'integration_quality': integration_quality,
            'quality_maintained': quality_maintained,
            'scalability_acceptable': scalability_acceptable,
            'details': {
                'clustering_result_summary': {
                    'cluster_count': len(clusters),
                    'temporal_coherence': clustering_result['temporal_coherence'],
                    'boundary_flexibility': clustering_result['boundary_flexibility']
                },
                'integration_result_summary': {
                    'hierarchical_coherence': integration_result['hierarchical_integration']['hierarchical_coherence'],
                    'temporal_flow_coherence': integration_result['temporal_coherence']['temporal_flow_coherence']
                }
            }
        }
        
        print(f"  å‡¦ç†æ™‚é–“: {total_time:.3f}ç§’")
        print(f"  å‡¦ç†é€Ÿåº¦: {concepts_per_second:.1f} concepts/sec")
        print(f"  ç”Ÿæˆã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ•°: {len(clusters)}")
        print(f"  ç¾è±¡å­¦çš„å¦¥å½“æ€§: {phenomenological_validity:.3f}")
        print(f"  çµ±åˆå“è³ª: {integration_quality:.3f}")
        print(f"  å“è³ªç¶­æŒ: {'âœ…' if quality_maintained else 'âŒ'}")
        print(f"  ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£: {'âœ…' if scalability_acceptable else 'âŒ'}")
        print(f"  ãƒ†ã‚¹ãƒˆçµæœ: {'âœ… PASS' if test_result['success'] else 'âŒ FAIL'}")
        
        return test_result
    
    def _evaluate_overall_results(self, test_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """å…¨ä½“çµæœã®è©•ä¾¡"""
        
        print("\n=== ç·åˆçµæœè©•ä¾¡ ===")
        
        # æˆåŠŸã—ãŸãƒ†ã‚¹ãƒˆã®æ•°
        passed_tests = [result for result in test_results if result['success']]
        total_tests = len(test_results)
        pass_rate = len(passed_tests) / total_tests
        
        # å„å“è³ªæŒ‡æ¨™ã®å¹³å‡
        avg_phenomenological_validity = np.mean([
            result.get('phenomenological_validity', 0) for result in test_results
        ])
        
        avg_temporal_coherence = np.mean([
            result.get('temporal_coherence', 0) for result in test_results
        ])
        
        avg_integration_quality = np.mean([
            result.get('integration_quality', 0) for result in test_results
        ])
        
        # å…¨ä½“çš„æˆåŠŸåˆ¤å®š
        overall_success = (
            pass_rate >= 0.8 and  # 80%ä»¥ä¸Šã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸ
            avg_phenomenological_validity > 0.6 and
            avg_temporal_coherence > 0.5
        )
        
        overall_result = {
            'overall_success': overall_success,
            'pass_rate': pass_rate,
            'passed_tests': len(passed_tests),
            'total_tests': total_tests,
            'avg_phenomenological_validity': avg_phenomenological_validity,
            'avg_temporal_coherence': avg_temporal_coherence,
            'avg_integration_quality': avg_integration_quality,
            'individual_results': test_results,
            'summary': {
                'dynamic_clustering_functional': any(
                    result['test_name'] in ['intentional_act_clustering', 'experiential_quality_clustering'] and result['success']
                    for result in test_results
                ),
                'temporal_integration_functional': any(
                    result['test_name'] in ['temporal_coherence_organization', 'multi_scale_temporal_integration'] and result['success']
                    for result in test_results
                ),
                'phenomenological_validity_maintained': avg_phenomenological_validity > 0.6,
                'performance_acceptable': any(
                    result['test_name'] == 'integrated_system_performance' and result['success']
                    for result in test_results
                )
            }
        }
        
        print(f"  ãƒ†ã‚¹ãƒˆæˆåŠŸç‡: {pass_rate:.1%} ({len(passed_tests)}/{total_tests})")
        print(f"  å¹³å‡ç¾è±¡å­¦çš„å¦¥å½“æ€§: {avg_phenomenological_validity:.3f}")
        print(f"  å¹³å‡æ™‚é–“çš„ä¸€è²«æ€§: {avg_temporal_coherence:.3f}")
        print(f"  å¹³å‡çµ±åˆå“è³ª: {avg_integration_quality:.3f}")
        print(f"  å‹•çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°: {'âœ…' if overall_result['summary']['dynamic_clustering_functional'] else 'âŒ'}")
        print(f"  æ™‚é–“çµ±åˆæ©Ÿèƒ½: {'âœ…' if overall_result['summary']['temporal_integration_functional'] else 'âŒ'}")
        print(f"  ç¾è±¡å­¦çš„å¦¥å½“æ€§: {'âœ…' if overall_result['summary']['phenomenological_validity_maintained'] else 'âŒ'}")
        print(f"  ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹: {'âœ…' if overall_result['summary']['performance_acceptable'] else 'âŒ'}")
        print(f"\n  ç·åˆè©•ä¾¡: {'ğŸ‰ SUCCESS' if overall_success else 'âš ï¸  NEEDS IMPROVEMENT'}")
        
        return overall_result


async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    
    print("å‹•çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("ç¾è±¡å­¦çš„ã«å¥å…¨ãªæ¦‚å¿µã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã¨å¤šã‚¹ã‚±ãƒ¼ãƒ«æ™‚é–“çµ±åˆã®æ¤œè¨¼")
    
    # ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
    test_suite = DynamicClusteringIntegrationTest()
    
    try:
        # åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
        results = await test_suite.run_comprehensive_tests()
        
        # çµæœã®ä¿å­˜ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        import json
        with open('/Users/yamaguchimitsuyuki/omoikane-lab/sandbox/tools/08_02_2025/dynamic_clustering_test_results.json', 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"\nçµæœãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: dynamic_clustering_test_results.json")
        
        return results
        
    except Exception as e:
        print(f"ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    # éåŒæœŸå®Ÿè¡Œ
    results = asyncio.run(main())