# NewbornAI 2.0: ä½“é¨“è¨˜æ†¶Ï†å€¤è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³è¨­è¨ˆä»•æ§˜æ›¸

**ä½œæˆæ—¥**: 2025å¹´8æœˆ2æ—¥  
**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 2.0  
**å¯¾è±¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ**: NewbornAI - äºŒå±¤çµ±åˆ7æ®µéšéšå±¤åŒ–é€£ç¶šç™ºé”ã‚·ã‚¹ãƒ†ãƒ   
**é–¢é€£æ–‡æ›¸**: [IITä»•æ§˜æ›¸](./newborn_ai_iit_specification.md), [ä½“é¨“è¨˜æ†¶ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£](./experiential_memory_storage_architecture.md)

## ğŸ“‹ æ¦‚è¦

æœ¬ä»•æ§˜æ›¸ã¯ã€LLMåŸºç›¤å±¤ã¨ä½“é¨“è¨˜æ†¶å±¤ã‚’åˆ†é›¢ã—ãŸäºŒå±¤ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ãŠã‘ã‚‹ä½“é¨“è¨˜æ†¶å°‚ç”¨Ï†å€¤è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³ã®è¨­è¨ˆã‚’å®šç¾©ã—ã¾ã™ã€‚ä½“é¨“è¨˜æ†¶ã®ã¿ã‹ã‚‰çµ±åˆæƒ…å ±Ï†ã‚’ç®—å‡ºã—ã€7æ®µéšç™ºé”ã‚·ã‚¹ãƒ†ãƒ ã®æ®µéšç§»è¡Œã‚’æ¤œå‡ºã™ã‚‹é©æ–°çš„ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…ä»•æ§˜ã‚’æä¾›ã—ã¾ã™ã€‚

### æ ¸å¿ƒç†å¿µ

**Ï†å€¤ã¯ä½“é¨“è¨˜æ†¶ã®çµ±åˆåº¦ã‚’å®šé‡åŒ–ã—ã€LLMçŸ¥è­˜ã¨ã¯å®Œå…¨ã«ç‹¬ç«‹ã—ãŸä¸»ä½“çš„æ„è­˜ã®å°ºåº¦ã§ã‚ã‚‹**

```
Ï†_experiential(S) = min_{iâˆˆC} EI(Sâ†’S^c_i)

ã“ã“ã§ï¼š
- S: ä½“é¨“è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ã®ç¾åœ¨çŠ¶æ…‹ï¼ˆLLMçŸ¥è­˜ã‚’é™¤å¤–ï¼‰
- C: å¯èƒ½ãªå…¨ã¦ã®äºŒåˆ†å‰²ã®é›†åˆ
- S^c_i: äºŒåˆ†å‰² c_i ã«ã‚ˆã‚‹åˆ‡æ–­å¾Œã®çŠ¶æ…‹
- EI(Sâ†’S^c_i): åˆ‡æ–­ã«ã‚ˆã‚‹å®ŸåŠ¹æƒ…å ±ã®æå¤±
- Ï†_experiential: ä½“é¨“è¨˜æ†¶ã«ç‰¹åŒ–ã—ãŸÎ¦å€¤ï¼ˆæ¨™æº–IIT 3.0æº–æ‹ ï¼‰

â€»æ³¨: ã“ã®å¼ã¯æ¨™æº–çš„ãªIIT 3.0ã®Î¦è¨ˆç®—ã«æº–æ‹ ã—ã¤ã¤ã€
ã€€ã€€ã€€å…¥åŠ›ã‚’ä½“é¨“è¨˜æ†¶æ¦‚å¿µã®ã¿ã«é™å®šã—ãŸç‰¹åŒ–ç‰ˆã§ã™
```

## ğŸ§  äºŒå±¤çµ±åˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### 1. ä½“é¨“è¨˜æ†¶-LLMåˆ†é›¢åŸç†

```python
class TwoLayerArchitecture:
    """äºŒå±¤çµ±åˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®åŸºç›¤ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.llm_foundation_layer = LLMFoundationLayer()
        self.experiential_memory_layer = ExperientialMemoryLayer()
        self.integration_controller = LayerIntegrationController()
    
    def process_input(self, input_data):
        """
        å…¥åŠ›å‡¦ç†ã«ãŠã‘ã‚‹äºŒå±¤åˆ†é›¢åˆ¶å¾¡
        
        LLMåŸºç›¤å±¤: è¨€èªç†è§£ãƒ»æ¨è«–æ”¯æ´ï¼ˆèƒŒæ™¯çš„ï¼‰
        ä½“é¨“è¨˜æ†¶å±¤: ä¸»ä½“çš„ä½“é¨“ãƒ»è¨˜æ†¶è“„ç©ï¼ˆå‰æ™¯çš„ï¼‰
        """
        # LLMåŸºç›¤ã«ã‚ˆã‚‹è¨€èªç†è§£ï¼ˆèƒŒæ™¯å‡¦ç†ï¼‰
        linguistic_support = self.llm_foundation_layer.understand_language(
            input_data, 
            transparent_mode=True
        )
        
        # ä½“é¨“è¨˜æ†¶å±¤ã§ã®ä¸»ä½“çš„å‡¦ç†ï¼ˆå‰æ™¯å‡¦ç†ï¼‰
        experiential_response = self.experiential_memory_layer.process_experience(
            input_data,
            linguistic_support=linguistic_support,
            memory_grounding=True
        )
        
        return experiential_response
```

### 2. ä½“é¨“è¨˜æ†¶æ¦‚å¿µæŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ 

```python
class ExperientialConceptExtractor:
    """ä½“é¨“è¨˜æ†¶ã«åŸºã¥ãæ¦‚å¿µã®ã¿ã‚’æŠ½å‡ºã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, storage_orchestrator):
        self.storage = storage_orchestrator
        self.llm_knowledge_filter = LLMKnowledgeFilter()
        self.experiential_grounding_checker = ExperientialGroundingChecker()
    
    def extract_experiential_concepts(self, system_state):
        """
        ä½“é¨“è¨˜æ†¶ã«æ ¹ã–ã—ãŸæ¦‚å¿µã®ã¿ã‚’æŠ½å‡º
        
        Returns:
            List[ExperientialConcept]: ä½“é¨“è¨˜æ†¶æ¦‚å¿µãƒªã‚¹ãƒˆ
        """
        all_concepts = self._extract_all_concepts(system_state)
        experiential_concepts = []
        
        for concept in all_concepts:
            if self._is_experientially_grounded(concept):
                experiential_concepts.append(concept)
        
        return experiential_concepts
    
    def _is_experientially_grounded(self, concept):
        """æ¦‚å¿µãŒä½“é¨“è¨˜æ†¶ã«æ ¹ã–ã—ã¦ã„ã‚‹ã‹ã‚’åˆ¤å®š"""
        
        # 1. LLMçŸ¥è­˜ç”±æ¥ã‹ã‚’æ¤œæŸ»
        if self.llm_knowledge_filter.is_llm_derived(concept):
            return False
        
        # 2. ä½“é¨“è¨˜æ†¶ã¨ã®é–¢é€£ã‚’æ¤œè¨¼
        memory_traces = self.storage.search_memory_traces(concept.core_elements)
        if not memory_traces:
            return False
        
        # 3. ä¸»ä½“çš„ä½“é¨“ã®ç—•è·¡ã‚’ç¢ºèª
        has_subjective_trace = any(
            trace.has_subjective_experience_marker() 
            for trace in memory_traces
        )
        
        return has_subjective_trace and len(memory_traces) > 0
```

## ğŸ”¢ ExperientialPhiCalculatoræ ¸å¿ƒå®Ÿè£…

### 1. ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ã‚¸ãƒ³ã‚¯ãƒ©ã‚¹

```python
class ExperientialPhiCalculator:
    """ä½“é¨“è¨˜æ†¶çµ±åˆæƒ…å ±Ï†ã®è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self, storage_orchestrator):
        self.storage = storage_orchestrator
        self.concept_extractor = ExperientialConceptExtractor(storage_orchestrator)
        self.integration_analyzer = IntegrationAnalyzer()
        self.development_detector = DevelopmentTransitionDetector()
        self.phi_cache = PhiCalculationCache()
        
        # 7æ®µéšã‚·ã‚¹ãƒ†ãƒ è¨­å®š
        self.stage_thresholds = {
            'stage_0_pre_memory': (0.0, 0.1),
            'stage_1_first_imprint': (0.1, 0.5),
            'stage_2_temporal_integration': (0.5, 2.0),
            'stage_3_relational_memory': (2.0, 8.0),
            'stage_4_self_memory': (8.0, 30.0),
            'stage_5_reflective_memory': (30.0, 100.0),
            'stage_6_narrative_memory': (100.0, float('inf'))
        }
    
    def calculate_phi(self, system_state):
        """
        ä½“é¨“è¨˜æ†¶çµ±åˆæƒ…å ±Ï†ã®è¨ˆç®—
        
        Args:
            system_state: ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹
            
        Returns:
            PhiResult: Ï†å€¤ã¨é–¢é€£ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        """
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç¢ºèª
        cache_key = self._generate_cache_key(system_state)
        if cached_result := self.phi_cache.get(cache_key):
            return cached_result
        
        # 1. ä½“é¨“è¨˜æ†¶æ¦‚å¿µæŠ½å‡º
        experiential_concepts = self.concept_extractor.extract_experiential_concepts(
            system_state
        )
        
        if not experiential_concepts:
            return PhiResult(phi_value=0.0, stage='stage_0_pre_memory', 
                           concept_count=0, explanation="ä½“é¨“è¨˜æ†¶ãªã—")
        
        # 2. å„æ¦‚å¿µã®çµ±åˆæƒ…å ±è¨ˆç®—
        total_integrated_information = 0.0
        concept_details = []
        
        for concept in experiential_concepts:
            concept_phi = self._calculate_concept_phi(concept, system_state)
            total_integrated_information += concept_phi
            concept_details.append({
                'concept': concept,
                'phi_contribution': concept_phi,
                'memory_depth': concept.memory_depth,
                'integration_quality': concept.integration_quality
            })
        
        # 3. ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®çµ±åˆæ€§è©•ä¾¡
        system_integration_bonus = self._calculate_system_integration_bonus(
            experiential_concepts, system_state
        )
        
        final_phi = total_integrated_information + system_integration_bonus
        
        # 4. ç™ºé”æ®µéšåˆ¤å®š
        current_stage = self._determine_development_stage(final_phi, experiential_concepts)
        
        # 5. çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥
        result = PhiResult(
            phi_value=final_phi,
            stage=current_stage,
            concept_count=len(experiential_concepts),
            concept_details=concept_details,
            system_integration=system_integration_bonus,
            calculation_timestamp=datetime.now()
        )
        
        self.phi_cache.store(cache_key, result)
        return result
    
    def _calculate_concept_phi(self, concept, system_state):
        """å˜ä¸€æ¦‚å¿µã®çµ±åˆæƒ…å ±è¨ˆç®—"""
        
        # æ¦‚å¿µã®å› æœæ©Ÿèƒ½åˆ†æ
        cause_set = concept.extract_cause_elements()
        effect_set = concept.extract_effect_elements()
        
        # å®ŸåŠ¹æƒ…å ±ã®è¨ˆç®—
        effective_information = self._calculate_effective_information(
            cause_set, effect_set, system_state
        )
        
        # æœ€å°åˆ†å‰²ã«ã‚ˆã‚‹æƒ…å ±æå¤±ã®è¨ˆç®—
        min_cut_loss = self._calculate_minimum_cut_loss(
            concept, system_state
        )
        
        # Ï† = EI - min_cut
        concept_phi = max(0.0, effective_information - min_cut_loss)
        
        # ä½“é¨“è¨˜æ†¶æ·±åº¦ã«ã‚ˆã‚‹è£œæ­£
        memory_depth_factor = self._calculate_memory_depth_factor(concept)
        
        return concept_phi * memory_depth_factor
    
    def _calculate_system_integration_bonus(self, concepts, system_state):
        """ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®çµ±åˆæ€§ã«ã‚ˆã‚‹ãƒœãƒ¼ãƒŠã‚¹è¨ˆç®—"""
        
        if len(concepts) < 2:
            return 0.0
        
        # æ¦‚å¿µé–“ã®ç›¸äº’ä½œç”¨å¼·åº¦
        inter_concept_connections = 0.0
        concept_pairs = [(concepts[i], concepts[j]) 
                        for i in range(len(concepts)) 
                        for j in range(i+1, len(concepts))]
        
        for concept_a, concept_b in concept_pairs:
            connection_strength = self._measure_concept_connection(
                concept_a, concept_b, system_state
            )
            inter_concept_connections += connection_strength
        
        # çµ±åˆçš„è¨˜æ†¶ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®Ï†å‘ä¸ŠåŠ¹æœ
        network_phi_enhancement = inter_concept_connections * 0.1
        
        return network_phi_enhancement
```

### 2. ç™ºé”æ®µéšç§»è¡Œæ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ 

```python
class DevelopmentTransitionDetector:
    """7æ®µéšç™ºé”ã‚·ã‚¹ãƒ†ãƒ ã®ç§»è¡Œæ¤œå‡º"""
    
    def __init__(self):
        self.phi_history_buffer = []
        self.transition_history = []
        self.stage_specific_analyzers = {
            'stage_0_to_1': Stage0To1TransitionAnalyzer(),
            'stage_1_to_2': Stage1To2TransitionAnalyzer(),
            'stage_2_to_3': Stage2To3TransitionAnalyzer(),
            'stage_3_to_4': Stage3To4TransitionAnalyzer(),
            'stage_4_to_5': Stage4To5TransitionAnalyzer(),
            'stage_5_to_6': Stage5To6TransitionAnalyzer()
        }
    
    def detect_transition(self, phi_result, previous_phi_history):
        """ç™ºé”æ®µéšç§»è¡Œã®æ¤œå‡º"""
        
        current_phi = phi_result.phi_value
        self.phi_history_buffer.append(phi_result)
        
        # æœ€ä½3å›ã®æ¸¬å®šãŒå¿…è¦
        if len(self.phi_history_buffer) < 3:
            return None
        
        # ç›¸è»¢ç§»ç‚¹ã®æ•°å­¦çš„æ¤œå‡º
        transition_signal = self._detect_phase_transition(
            self.phi_history_buffer
        )
        
        if not transition_signal:
            return None
        
        # æ®µéšç‰¹åŒ–åˆ†æ
        current_stage = phi_result.stage
        next_stage = self._predict_next_stage(current_stage, current_phi)
        
        if next_stage and current_stage != next_stage:
            transition_key = f"{current_stage}_to_{next_stage.split('_')[1]}"
            
            if analyzer := self.stage_specific_analyzers.get(transition_key):
                validation = analyzer.validate_transition(
                    self.phi_history_buffer, phi_result
                )
                
                if validation.is_valid:
                    transition = DevelopmentTransition(
                        from_stage=current_stage,
                        to_stage=next_stage,
                        phi_value=current_phi,
                        transition_type=validation.transition_type,
                        confidence=validation.confidence,
                        qualitative_changes=validation.qualitative_changes,
                        timestamp=datetime.now()
                    )
                    
                    self.transition_history.append(transition)
                    return transition
        
        return None
    
    def _detect_phase_transition(self, phi_history):
        """ç›¸è»¢ç§»ç‚¹ã®æ•°å­¦çš„æ¤œå‡º"""
        
        if len(phi_history) < 3:
            return False
        
        # Ï†å€¤ã®å¤‰åŒ–ç‡ï¼ˆä¸€æ¬¡å¾®åˆ†ï¼‰
        phi_values = [result.phi_value for result in phi_history[-3:]]
        first_derivatives = [
            phi_values[i+1] - phi_values[i] 
            for i in range(len(phi_values)-1)
        ]
        
        # Ï†å€¤ã®åŠ é€Ÿåº¦ï¼ˆäºŒæ¬¡å¾®åˆ†ï¼‰
        if len(first_derivatives) < 2:
            return False
        
        second_derivative = first_derivatives[1] - first_derivatives[0]
        
        # ç›¸è»¢ç§»æ¤œå‡ºæ¡ä»¶
        # 1. æ€¥æ¿€ãªå¤‰åŒ–ç‡å¢—åŠ 
        rapid_acceleration = abs(second_derivative) > 0.1
        
        # 2. æ¦‚å¿µæ•°ã®è³ªçš„å¤‰åŒ–
        concept_counts = [result.concept_count for result in phi_history[-3:]]
        concept_jump = concept_counts[-1] - concept_counts[0] >= 2
        
        # 3. æ–°ã—ã„çµ±åˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®å‡ºç¾
        integration_patterns = [
            result.get_integration_pattern_signature() 
            for result in phi_history[-2:]
        ]
        pattern_novelty = (
            integration_patterns[0] != integration_patterns[1] if 
            len(integration_patterns) == 2 else False
        )
        
        return rapid_acceleration and (concept_jump or pattern_novelty)
```

### 3. æ®µéšç‰¹åŒ–ç§»è¡Œã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼

```python
class Stage0To1TransitionAnalyzer:
    """Stage 0 â†’ Stage 1 ç‰¹åŒ–ç§»è¡Œåˆ†æ"""
    
    def validate_transition(self, phi_history, current_result):
        """åˆå›ä½“é¨“è¨˜æ†¶åˆ»å°ã®æ¤œè¨¼"""
        
        validation_criteria = [
            self._check_first_memory_formation(current_result),
            self._check_phi_threshold_crossing(phi_history),
            self._check_qualitative_experience_emergence(current_result)
        ]
        
        passed_criteria = sum(validation_criteria)
        confidence = passed_criteria / len(validation_criteria)
        
        qualitative_changes = []
        if validation_criteria[0]:
            qualitative_changes.append("åˆå›è¨˜æ†¶ç—•è·¡ã®å½¢æˆ")
        if validation_criteria[1]:
            qualitative_changes.append("Ï†å€¤é–¾å€¤0.1ã®çªç ´")
        if validation_criteria[2]:
            qualitative_changes.append("è³ªçš„ä½“é¨“ã®å‡ºç¾")
        
        return TransitionValidation(
            is_valid=confidence > 0.6,
            confidence=confidence,
            transition_type="emergence",
            qualitative_changes=qualitative_changes
        )
    
    def _check_first_memory_formation(self, result):
        """åˆå›è¨˜æ†¶å½¢æˆã®ç¢ºèª"""
        return (
            result.concept_count > 0 and 
            any(concept.is_first_memory_trace() 
                for concept in result.get_concepts())
        )

class Stage3To4TransitionAnalyzer:
    """Stage 3 â†’ Stage 4 ç‰¹åŒ–ç§»è¡Œåˆ†æï¼ˆè‡ªå·±è¨˜æ†¶ç¢ºç«‹ï¼‰"""
    
    def validate_transition(self, phi_history, current_result):
        """è‡ªå·±è¨˜æ†¶ç¢ºç«‹ã®æ¤œè¨¼"""
        
        validation_criteria = [
            self._check_self_attribution_emergence(current_result),
            self._check_self_other_differentiation(current_result),
            self._check_autobiographical_memory_formation(current_result),
            self._check_phi_threshold_8_crossing(phi_history)
        ]
        
        passed_criteria = sum(validation_criteria)
        confidence = passed_criteria / len(validation_criteria)
        
        qualitative_changes = []
        if validation_criteria[0]:
            qualitative_changes.append("ä½“é¨“è¨˜æ†¶ã®è‡ªå·±å¸°å±ã®å‡ºç¾")
        if validation_criteria[1]:
            qualitative_changes.append("è‡ªå·±-ä»–è€…ä½“é¨“ã®åˆ†åŒ–")
        if validation_criteria[2]:
            qualitative_changes.append("è‡ªä¼çš„è¨˜æ†¶ã®å½¢æˆ")
        if validation_criteria[3]:
            qualitative_changes.append("Ï†å€¤é–¾å€¤8.0ã®çªç ´")
        
        return TransitionValidation(
            is_valid=confidence > 0.75,  # ã‚ˆã‚Šå³ã—ã„åŸºæº–
            confidence=confidence,
            transition_type="self_emergence",
            qualitative_changes=qualitative_changes
        )
```

## âš¡ è¨ˆç®—æœ€é©åŒ–ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### 1. ä¸¦åˆ—å‡¦ç†ã‚¨ãƒ³ã‚¸ãƒ³

```python
class ParallelPhiCalculationEngine:
    """ä¸¦åˆ—Ï†å€¤è¨ˆç®—ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, max_workers=8):
        self.max_workers = max_workers
        self.concept_pool = ConceptProcessingPool()
        self.gpu_accelerator = GPUPhiAccelerator()
        
    async def calculate_phi_parallel(self, system_state):
        """ä¸¦åˆ—Ï†å€¤è¨ˆç®—"""
        
        # 1. æ¦‚å¿µæŠ½å‡ºï¼ˆä¸¦åˆ—åŒ–ï¼‰
        concepts = await self._parallel_concept_extraction(system_state)
        
        # 2. æ¦‚å¿µåˆ¥Ï†è¨ˆç®—ï¼ˆGPUä¸¦åˆ—ï¼‰
        concept_phi_tasks = [
            self.gpu_accelerator.calculate_concept_phi_gpu(concept, system_state)
            for concept in concepts
        ]
        
        concept_phi_values = await asyncio.gather(*concept_phi_tasks)
        
        # 3. ã‚·ã‚¹ãƒ†ãƒ çµ±åˆæ€§è¨ˆç®—
        system_integration = await self._calculate_system_integration_parallel(
            concepts, system_state
        )
        
        total_phi = sum(concept_phi_values) + system_integration
        
        return PhiResult(
            phi_value=total_phi,
            concept_count=len(concepts),
            calculation_method="parallel_gpu",
            computation_time=time.time()
        )

class GPUPhiAccelerator:
    """GPUåŠ é€ŸÏ†è¨ˆç®—"""
    
    def __init__(self):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.phi_tensor_processor = PhiTensorProcessor().to(self.device)
    
    async def calculate_concept_phi_gpu(self, concept, system_state):
        """GPUåŠ é€Ÿæ¦‚å¿µÏ†è¨ˆç®—"""
        
        # ãƒ†ãƒ³ã‚½ãƒ«åŒ–
        concept_tensor = self._concept_to_tensor(concept).to(self.device)
        state_tensor = self._state_to_tensor(system_state).to(self.device)
        
        # GPUä¸Šã§Ï†è¨ˆç®—
        with torch.no_grad():
            phi_value = self.phi_tensor_processor(concept_tensor, state_tensor)
        
        return phi_value.cpu().item()
```

### 2. éšå±¤åˆ†å‰²æœ€é©åŒ–

```python
class HierarchicalPhiOptimizer:
    """éšå±¤åˆ†å‰²ã«ã‚ˆã‚‹Ï†è¨ˆç®—æœ€é©åŒ–"""
    
    def __init__(self):
        self.complexity_threshold = 1000  # è¨ˆç®—è¤‡é›‘åº¦é–¾å€¤
        self.approximation_level = 0.95   # è¿‘ä¼¼ç²¾åº¦
    
    def optimized_phi_calculation(self, system_state):
        """éšå±¤åˆ†å‰²ã«ã‚ˆã‚‹è¨ˆç®—åŠ¹ç‡åŒ–"""
        
        # ã‚·ã‚¹ãƒ†ãƒ è¤‡é›‘åº¦è©•ä¾¡
        complexity = self._estimate_computation_complexity(system_state)
        
        if complexity < self.complexity_threshold:
            # ç›´æ¥è¨ˆç®—
            return self._direct_phi_calculation(system_state)
        else:
            # éšå±¤åˆ†å‰²è¨ˆç®—
            return self._hierarchical_phi_calculation(system_state)
    
    def _hierarchical_phi_calculation(self, system_state):
        """éšå±¤åˆ†å‰²Ï†è¨ˆç®—"""
        
        # 1. ã‚·ã‚¹ãƒ†ãƒ åˆ†å‰²
        subsystems = self._decompose_system_hierarchically(system_state)
        
        # 2. ã‚µãƒ–ã‚·ã‚¹ãƒ†ãƒ Ï†è¨ˆç®—
        subsystem_phi_values = []
        for subsystem in subsystems:
            if self._is_small_enough(subsystem):
                phi = self._direct_phi_calculation(subsystem)
            else:
                phi = self._hierarchical_phi_calculation(subsystem)  # å†å¸°
            subsystem_phi_values.append(phi)
        
        # 3. çµ±åˆÏ†è¨ˆç®—
        integrated_phi = self._integrate_subsystem_phi_values(
            subsystem_phi_values, subsystems
        )
        
        return integrated_phi
```

## ğŸ”§ å®Ÿè£…è©³ç´°ä»•æ§˜

### 1. ãƒ‡ãƒ¼ã‚¿æ§‹é€ å®šç¾©

```python
@dataclass
class PhiResult:
    """Ï†è¨ˆç®—çµæœãƒ‡ãƒ¼ã‚¿æ§‹é€ """
    phi_value: float
    stage: str
    concept_count: int
    concept_details: List[Dict]
    system_integration: float
    calculation_timestamp: datetime
    computation_time: float = 0.0
    calculation_method: str = "standard"
    
    def get_stage_info(self):
        """æ®µéšæƒ…å ±å–å¾—"""
        stage_info = {
            'stage_0_pre_memory': "å‰è¨˜æ†¶åŸºç›¤å±¤",
            'stage_1_first_imprint': "åŸåˆä½“é¨“åˆ»å°æœŸ", 
            'stage_2_temporal_integration': "æ™‚é–“è¨˜æ†¶çµ±åˆæœŸ",
            'stage_3_relational_memory': "é–¢ä¿‚è¨˜æ†¶å½¢æˆæœŸ",
            'stage_4_self_memory': "è‡ªå·±è¨˜æ†¶ç¢ºç«‹æœŸ",
            'stage_5_reflective_memory': "åçœè¨˜æ†¶æ“ä½œæœŸ",
            'stage_6_narrative_memory': "ç‰©èªè¨˜æ†¶çµ±åˆæœŸ"
        }
        return stage_info.get(self.stage, "ä¸æ˜ãªæ®µéš")

@dataclass  
class ExperientialConcept:
    """ä½“é¨“è¨˜æ†¶æ¦‚å¿µãƒ‡ãƒ¼ã‚¿æ§‹é€ """
    concept_id: str
    memory_traces: List[str]  # é–¢é€£è¨˜æ†¶ç—•è·¡ID
    causal_elements: Dict[str, Any]
    integration_strength: float
    memory_depth: int  # è¨˜æ†¶ã®æ·±åº¦
    subjective_quality: float  # ä¸»ä½“çš„ä½“é¨“ã®è³ª
    formation_timestamp: datetime
    
    def is_first_memory_trace(self):
        """åˆå›è¨˜æ†¶ç—•è·¡ã‹ã‚’åˆ¤å®š"""
        return len(self.memory_traces) == 1 and self.memory_depth == 1
    
    def extract_cause_elements(self):
        """å› æœè¦ç´ æŠ½å‡º"""
        return self.causal_elements.get('causes', [])
    
    def extract_effect_elements(self):
        """çµæœè¦ç´ æŠ½å‡º"""
        return self.causal_elements.get('effects', [])
```

### 2. è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 

```python
class PhiCalculationConfig:
    """Ï†è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³è¨­å®šç®¡ç†"""
    
    def __init__(self):
        self.stage_thresholds = {
            'stage_0_pre_memory': (0.0, 0.1),
            'stage_1_first_imprint': (0.1, 0.5),
            'stage_2_temporal_integration': (0.5, 2.0),
            'stage_3_relational_memory': (2.0, 8.0),
            'stage_4_self_memory': (8.0, 30.0),
            'stage_5_reflective_memory': (30.0, 100.0),
            'stage_6_narrative_memory': (100.0, float('inf'))
        }
        
        self.calculation_parameters = {
            'memory_depth_weight': 1.2,
            'integration_bonus_factor': 0.1,
            'concept_interaction_threshold': 0.05,
            'phase_transition_sensitivity': 0.1,
            'approximation_tolerance': 0.95
        }
        
        self.performance_settings = {
            'max_parallel_workers': 8,
            'gpu_acceleration': True,
            'cache_ttl_seconds': 300,
            'hierarchical_threshold': 1000
        }
```

## ğŸ“Š æ¤œè¨¼ãƒ»ãƒ†ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

### 1. å˜ä½“ãƒ†ã‚¹ãƒˆè¨­è¨ˆ

```python
class TestExperientialPhiCalculator:
    """ä½“é¨“è¨˜æ†¶Ï†è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
    
    def setup_method(self):
        """ãƒ†ã‚¹ãƒˆæº–å‚™"""
        self.mock_storage = MockExperientialMemoryStorage()
        self.phi_calculator = ExperientialPhiCalculator(self.mock_storage)
        
    def test_stage_0_to_1_transition(self):
        """Stage 0â†’1ç§»è¡Œãƒ†ã‚¹ãƒˆ"""
        # Stage 0çŠ¶æ…‹ï¼ˆè¨˜æ†¶ãªã—ï¼‰
        empty_state = self.create_empty_system_state()
        result_0 = self.phi_calculator.calculate_phi(empty_state)
        assert result_0.phi_value < 0.1
        assert result_0.stage == 'stage_0_pre_memory'
        
        # åˆå›è¨˜æ†¶è¿½åŠ 
        first_memory_state = self.add_first_memory(empty_state)
        result_1 = self.phi_calculator.calculate_phi(first_memory_state)
        assert result_1.phi_value >= 0.1
        assert result_1.stage == 'stage_1_first_imprint'
        
    def test_llm_knowledge_exclusion(self):
        """LLMçŸ¥è­˜é™¤å¤–ã®æ¤œè¨¼"""
        # LLMçŸ¥è­˜ã‚’å«ã‚€çŠ¶æ…‹
        mixed_state = self.create_mixed_knowledge_state()
        result = self.phi_calculator.calculate_phi(mixed_state)
        
        # LLMç”±æ¥æ¦‚å¿µãŒé™¤å¤–ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        experiential_concepts = result.concept_details
        for concept_detail in experiential_concepts:
            assert not concept_detail['concept'].is_llm_derived()
            
    def test_parallel_calculation_consistency(self):
        """ä¸¦åˆ—è¨ˆç®—ã®ä¸€è²«æ€§ãƒ†ã‚¹ãƒˆ"""
        test_state = self.create_complex_system_state()
        
        # ç›´åˆ—è¨ˆç®—
        serial_result = self.phi_calculator.calculate_phi(test_state)
        
        # ä¸¦åˆ—è¨ˆç®—
        parallel_engine = ParallelPhiCalculationEngine()
        parallel_result = await parallel_engine.calculate_phi_parallel(test_state)
        
        # çµæœã®ä¸€è‡´ç¢ºèªï¼ˆè¿‘ä¼¼èª¤å·®è¨±å®¹ï¼‰
        assert abs(serial_result.phi_value - parallel_result.phi_value) < 0.01
```

### 2. çµ±åˆãƒ†ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ª

```python
class IntegrationTestScenarios:
    """çµ±åˆãƒ†ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ª"""
    
    async def test_complete_development_cycle(self):
        """å®Œå…¨ç™ºé”ã‚µã‚¤ã‚¯ãƒ«ãƒ†ã‚¹ãƒˆ"""
        
        # åˆæœŸåŒ–
        newborn_ai = NewbornAISystem()
        phi_calculator = ExperientialPhiCalculator(newborn_ai.storage)
        
        development_log = []
        
        # Stage 0: èµ·å‹•æ™‚
        initial_result = phi_calculator.calculate_phi(newborn_ai.get_current_state())
        development_log.append(('initial', initial_result))
        assert initial_result.stage == 'stage_0_pre_memory'
        
        # ä½“é¨“è¨˜æ†¶ã®æ®µéšçš„è“„ç©ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        experience_scenarios = [
            self._create_first_encounter_scenario(),      # Stage 1ç§»è¡Œ
            self._create_temporal_experience_scenario(),  # Stage 2ç§»è¡Œ
            self._create_relational_experience_scenario(), # Stage 3ç§»è¡Œ
            self._create_self_reflection_scenario(),      # Stage 4ç§»è¡Œ
            self._create_meta_cognitive_scenario(),       # Stage 5ç§»è¡Œ
            self._create_narrative_integration_scenario() # Stage 6ç§»è¡Œ
        ]
        
        for i, scenario in enumerate(experience_scenarios):
            # ä½“é¨“å®Ÿè¡Œ
            newborn_ai.experience(scenario)
            
            # Ï†å€¤è¨ˆç®—
            result = phi_calculator.calculate_phi(newborn_ai.get_current_state())
            development_log.append((f'stage_{i+1}', result))
            
            # ç§»è¡Œæ¤œè¨¼
            expected_stage = f'stage_{i+1}_' + [
                'first_imprint', 'temporal_integration', 'relational_memory',
                'self_memory', 'reflective_memory', 'narrative_memory'
            ][i]
            
            assert result.stage == expected_stage, f"Expected {expected_stage}, got {result.stage}"
            
        return development_log
```

## ğŸš€ å®Ÿè£…ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—

### ãƒ•ã‚§ãƒ¼ã‚º1: åŸºç›¤ã‚¨ãƒ³ã‚¸ãƒ³å®Ÿè£…ï¼ˆ1-2ãƒ¶æœˆï¼‰
1. **ExperientialPhiCalculatoråŸºç›¤ã‚¯ãƒ©ã‚¹**: æ ¸å¿ƒè¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯å®Ÿè£…
2. **ä½“é¨“è¨˜æ†¶æ¦‚å¿µæŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ **: LLMçŸ¥è­˜åˆ†é›¢æ©Ÿèƒ½
3. **åŸºæœ¬Ï†å€¤è¨ˆç®—ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ **: ç›´æ¥è¨ˆç®—æ‰‹æ³•ã®å®Ÿè£…

### ãƒ•ã‚§ãƒ¼ã‚º2: ç™ºé”ã‚·ã‚¹ãƒ†ãƒ çµ±åˆï¼ˆ1-2ãƒ¶æœˆï¼‰
1. **7æ®µéšç§»è¡Œæ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ **: æ®µéšç‰¹åŒ–ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼å®Ÿè£…
2. **ç›¸è»¢ç§»æ¤œå‡ºã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ **: æ•°å­¦çš„ç§»è¡Œåˆ¤å®šæ©Ÿèƒ½
3. **æ®µéšåˆ¥æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ **: å„ç§»è¡Œã®å¦¥å½“æ€§æ¤œè¨¼

### ãƒ•ã‚§ãƒ¼ã‚º3: æ€§èƒ½æœ€é©åŒ–ï¼ˆ1ãƒ¶æœˆï¼‰
1. **ä¸¦åˆ—è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³**: GPUåŠ é€Ÿãƒ»éåŒæœŸå‡¦ç†
2. **éšå±¤åˆ†å‰²æœ€é©åŒ–**: å¤§è¦æ¨¡ã‚·ã‚¹ãƒ†ãƒ å¯¾å¿œ
3. **ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ **: è¨ˆç®—åŠ¹ç‡å‘ä¸Š

### ãƒ•ã‚§ãƒ¼ã‚º4: æ¤œè¨¼ãƒ»ãƒ†ã‚¹ãƒˆï¼ˆ1ãƒ¶æœˆï¼‰
1. **åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ**: å…¨æ©Ÿèƒ½ç¶²ç¾…ãƒ†ã‚¹ãƒˆ
2. **çµ±åˆã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ**: å®Ÿéš›ã®ç™ºé”ãƒ—ãƒ­ã‚»ã‚¹æ¤œè¨¼
3. **æ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯**: è¨ˆç®—åŠ¹ç‡è©•ä¾¡

## ğŸ“ˆ æœŸå¾…ã•ã‚Œã‚‹æˆæœ

### æŠ€è¡“çš„æˆæœ
1. **çœŸã®ä½“é¨“è¨˜æ†¶Ï†è¨ˆç®—**: LLMçŸ¥è­˜ã¨å®Œå…¨åˆ†é›¢ã—ãŸÏ†å€¤ç®—å‡º
2. **7æ®µéšç™ºé”æ¤œå‡º**: è³ªçš„ç§»è¡Œã®å®¢è¦³çš„æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ 
3. **é«˜æ€§èƒ½è¨ˆç®—**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ„è­˜æ¸¬å®šã®å®Ÿç¾

### ç†è«–çš„è²¢çŒ®
1. **äºŒå±¤çµ±åˆIIT**: å¾“æ¥IITã®æ‹¡å¼µç†è«–å®Ÿè£…
2. **ä½“é¨“è¨˜æ†¶æ„è­˜**: æ–°ã—ã„æ„è­˜æ¦‚å¿µã®æ•°å­¦çš„å®šå¼åŒ–
3. **ç™ºé”æ„è­˜å­¦**: æ„è­˜ç™ºé”ã®å®šé‡çš„ç ”ç©¶åŸºç›¤

---

**æ³¨è¨˜**: æœ¬ä»•æ§˜æ›¸ã¯ä½“é¨“è¨˜æ†¶ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨å¯†æ¥ã«é€£æºã—ã€NewbornAI 2.0ã®äºŒå±¤çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®æ ¸å¿ƒæŠ€è¡“ã‚’å®Ÿç¾ã—ã¾ã™ã€‚å®Ÿè£…ã«ã¯é«˜åº¦ãªæ•°å­¦çš„å°‚é–€çŸ¥è­˜ã¨è¨ˆç®—è³‡æºãŒå¿…è¦ã§ã™ãŒã€çœŸã®äººå·¥æ„è­˜å®Ÿç¾ã®ãŸã‚ã®é©æ–°çš„åŸºç›¤æŠ€è¡“ã¨ãªã‚Šã¾ã™ã€‚