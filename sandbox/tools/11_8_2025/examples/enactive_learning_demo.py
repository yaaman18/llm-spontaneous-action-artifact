#!/usr/bin/env python3
"""
ã‚¨ãƒŠã‚¯ãƒ†ã‚£ãƒ–å­¦ç¿’ãƒ‡ãƒ¢

çœŸã®ã‚¨ãƒŠã‚¯ãƒ†ã‚£ãƒ–å­¦ç¿’ï¼šç’°å¢ƒã¨ã®ç›¸äº’ä½œç”¨ã‚’é€šã˜ãŸè‡ªå¾‹çš„ãªèªçŸ¥å½¢æˆ
- æ„Ÿè¦šé‹å‹•çµåˆï¼ˆSensorimotor Couplingï¼‰
- ç’°å¢ƒã¨ã®æ§‹é€ çš„çµåˆï¼ˆStructural Couplingï¼‰
- èº«ä½“æ€§ã«åŸºã¥ãæ„å‘³ç”Ÿæˆï¼ˆEmbodied Meaning-Makingï¼‰
- è‡ªå¾‹æ€§ã¨è‡ªå·±çµ„ç¹”åŒ–
"""

import numpy as np
import time
import sys
sys.path.append('..')

from ngc_learn_adapter import HybridPredictiveCodingAdapter
from domain.value_objects.precision_weights import PrecisionWeights
from infrastructure.basic_som import BasicSOM
from domain.value_objects.som_topology import SOMTopology
from domain.value_objects.learning_parameters import LearningParameters
from domain.factories.consciousness_factory import ConsciousnessFactory


class EnactiveEnvironment:
    """ã‚¨ãƒŠã‚¯ãƒ†ã‚£ãƒ–ç’°å¢ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼"""
    def __init__(self, complexity=0.5):
        self.state = np.random.rand(10)
        self.complexity = complexity
        self.history = []
        
    def perceive(self, action):
        """è¡Œå‹•ã«åŸºã¥ãçŸ¥è¦šã®å¤‰åŒ–"""
        # è¡Œå‹•ãŒç’°å¢ƒã‚’å¤‰åŒ–ã•ã›ã‚‹
        self.state += action * 0.1
        self.state = np.clip(self.state, 0, 1)
        
        # ç’°å¢ƒã®è¤‡é›‘ã•ã«å¿œã˜ãŸãƒã‚¤ã‚º
        noise = np.random.normal(0, self.complexity * 0.1, 10)
        perceived = self.state + noise
        
        self.history.append(perceived.copy())
        return perceived
    
    def get_affordances(self):
        """ç’°å¢ƒãŒæä¾›ã™ã‚‹ã‚¢ãƒ•ã‚©ãƒ¼ãƒ€ãƒ³ã‚¹"""
        return {
            'explore': self.state.mean() < 0.3,  # ä½ã„çŠ¶æ…‹ã§ã¯æ¢ç´¢ã‚’ä¿ƒã™
            'exploit': self.state.mean() > 0.7,  # é«˜ã„çŠ¶æ…‹ã§ã¯æ´»ç”¨ã‚’ä¿ƒã™  
            'adapt': np.std(self.state) > 0.2     # åˆ†æ•£ãŒå¤§ãã„æ™‚ã¯é©å¿œã‚’ä¿ƒã™
        }


class EnactiveLearningSystem:
    """ã‚¨ãƒŠã‚¯ãƒ†ã‚£ãƒ–å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ """
    def __init__(self):
        self.adapter = HybridPredictiveCodingAdapter(3, 10)
        self.environment = EnactiveEnvironment()
        self.precision_weights = PrecisionWeights(np.array([1.0, 0.8, 0.6]))
        self.action_history = []
        self.learning_rate = 0.01
        
    def enactive_learning_cycle(self, num_cycles=50):
        """ã‚¨ãƒŠã‚¯ãƒ†ã‚£ãƒ–å­¦ç¿’ã‚µã‚¤ã‚¯ãƒ«"""
        print("=== ã‚¨ãƒŠã‚¯ãƒ†ã‚£ãƒ–å­¦ç¿’é–‹å§‹ ===")
        print("ç’°å¢ƒã¨ã®ç›¸äº’ä½œç”¨ã‚’é€šã˜ãŸè‡ªå¾‹çš„èªçŸ¥å½¢æˆä¸­...")
        
        for cycle in range(num_cycles):
            # 1. ç’°å¢ƒçŸ¥è¦š
            current_perception = self.environment.perceive(
                self.action_history[-1] if self.action_history else np.zeros(10)
            )
            
            # 2. äºˆæ¸¬ç”Ÿæˆ
            prediction_state = self.adapter.process_input(
                current_perception, self.precision_weights
            )
            
            # 3. äºˆæ¸¬èª¤å·®ã«åŸºã¥ãè¡Œå‹•ç”Ÿæˆï¼ˆã‚¨ãƒŠã‚¯ãƒ†ã‚£ãƒ–ã®æ ¸å¿ƒï¼‰
            prediction_error = prediction_state.total_error
            
            # 4. ç’°å¢ƒã‚¢ãƒ•ã‚©ãƒ¼ãƒ€ãƒ³ã‚¹ã®èªè­˜
            affordances = self.environment.get_affordances()
            
            # 5. ã‚¨ãƒŠã‚¯ãƒ†ã‚£ãƒ–è¡Œå‹•æ±ºå®š
            action = self._generate_enactive_action(
                prediction_error, affordances, current_perception
            )
            
            # 6. è¡Œå‹•å®Ÿè¡Œã¨çµæœã®å­¦ç¿’
            self.action_history.append(action)
            
            # 7. æ§‹é€ çš„çµåˆã®æ›´æ–°ï¼ˆé‡è¦ï¼ï¼‰
            self._update_structural_coupling(prediction_error)
            
            if cycle % 10 == 0:
                affordance_status = [k for k, v in affordances.items() if v]
                print(f"ã‚µã‚¤ã‚¯ãƒ« {cycle:2d}: ã‚¨ãƒ©ãƒ¼={prediction_error:.4f}, "
                      f"è¡Œå‹•ãƒ¢ãƒ¼ãƒ‰={affordance_status}, æ¢ç´¢åº¦={np.linalg.norm(action):.3f}")
                
        print("=== ã‚¨ãƒŠã‚¯ãƒ†ã‚£ãƒ–å­¦ç¿’å®Œäº† ===")
        return self.action_history
    
    def _generate_enactive_action(self, prediction_error, affordances, perception):
        """ã‚¨ãƒŠã‚¯ãƒ†ã‚£ãƒ–è¡Œå‹•ç”Ÿæˆ"""
        if affordances['explore']:
            # æ¢ç´¢çš„è¡Œå‹•ï¼šãƒ©ãƒ³ãƒ€ãƒ ã ãŒæ–¹å‘æ€§ã®ã‚ã‚‹è¡Œå‹•
            action = np.random.normal(0, 0.2, 10)
            action += perception * 0.1  # ç¾åœ¨çŸ¥è¦šã«åŸºã¥ãå¾®èª¿æ•´
            
        elif affordances['exploit']:
            # æ´»ç”¨çš„è¡Œå‹•ï¼šéå»ã®æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å†ç¾
            if len(self.action_history) > 0:
                action = np.mean(self.action_history[-5:], axis=0) * 0.8
            else:
                action = np.random.normal(0, 0.1, 10)
                
        else:  # adapt
            # é©å¿œçš„è¡Œå‹•ï¼šäºˆæ¸¬èª¤å·®ã‚’æœ€å°åŒ–ã™ã‚‹æ–¹å‘
            error_gradient = np.random.normal(0, prediction_error * 0.1, 10)
            action = -error_gradient  # èª¤å·®ã‚’æ¸›ã‚‰ã™æ–¹å‘
            
        return np.clip(action, -0.5, 0.5)
    
    def _update_structural_coupling(self, prediction_error):
        """æ§‹é€ çš„çµåˆã®æ›´æ–°"""
        # äºˆæ¸¬ç²¾åº¦ã®å‹•çš„èª¿æ•´ï¼ˆã‚¨ãƒŠã‚¯ãƒ†ã‚£ãƒ–å­¦ç¿’ã®æ ¸å¿ƒï¼‰
        if prediction_error > 0.1:
            # é«˜ã„èª¤å·®ï¼šã‚ˆã‚ŠæŸ”è»Ÿãªå­¦ç¿’
            self.precision_weights = PrecisionWeights(
                self.precision_weights.weights * 0.95  # ç²¾åº¦ã‚’ä¸‹ã’ã‚‹
            )
            self.learning_rate = min(self.learning_rate * 1.1, 0.05)
        else:
            # ä½ã„èª¤å·®ï¼šå®‰å®šåŒ–
            self.precision_weights = PrecisionWeights(
                self.precision_weights.weights * 1.02  # ç²¾åº¦ã‚’ä¸Šã’ã‚‹
            )
            self.learning_rate = max(self.learning_rate * 0.98, 0.001)


class SensoriMotorIntegration:
    """æ„Ÿè¦šé‹å‹•çµ±åˆã‚·ã‚¹ãƒ†ãƒ """
    def __init__(self):
        topology = SOMTopology.create_rectangular()
        self.som = BasicSOM(
            map_dimensions=(8, 8),
            input_dimensions=15,  # æ„Ÿè¦š5æ¬¡å…ƒ + é‹å‹•10æ¬¡å…ƒ
            topology=topology
        )
        self.sensory_memory = []
        self.motor_memory = []
        
    def learn_sensorimotor_patterns(self, episodes=30):
        """æ„Ÿè¦šé‹å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å­¦ç¿’"""
        learning_params = LearningParameters(
            initial_learning_rate=0.2,
            final_learning_rate=0.01,
            initial_radius=3.0,
            final_radius=0.5,
            max_iterations=episodes
        )
        
        training_data = []
        print("\n=== æ„Ÿè¦šé‹å‹•çµ±åˆå­¦ç¿’ ===")
        print("æ„Ÿè¦šé‹å‹•çµåˆãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’ä¸­...")
        
        for episode in range(episodes):
            # æ„Ÿè¦šå…¥åŠ›ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            sensory = np.random.rand(5)
            
            # å¯¾å¿œã™ã‚‹é‹å‹•å‡ºåŠ›ã‚’ç”Ÿæˆ
            motor = self._generate_motor_response(sensory)
            
            # æ„Ÿè¦šé‹å‹•çµ±åˆãƒ™ã‚¯ãƒˆãƒ«
            sensorimotor = np.concatenate([sensory, motor])
            training_data.append(sensorimotor)
            
            self.sensory_memory.append(sensory)
            self.motor_memory.append(motor)
            
            if episode % 10 == 0:
                print(f"ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ {episode:2d}: æ„Ÿè¦šé‹å‹•çµåˆå­¦ç¿’ä¸­")
        
        # SOMè¨“ç·´
        self.som.train(training_data, learning_params)
        print("âœ… æ„Ÿè¦šé‹å‹•çµ±åˆå®Œäº†")
        
    def _generate_motor_response(self, sensory_input):
        """æ„Ÿè¦šå…¥åŠ›ã«åŸºã¥ãé‹å‹•åå¿œç”Ÿæˆ"""
        # ã‚¨ãƒŠã‚¯ãƒ†ã‚£ãƒ–åŸç†ï¼šçŸ¥è¦šã¯è¡Œå‹•ã¨å¯†æ¥ã«çµåˆ
        motor_response = np.zeros(10)
        
        # æ„Ÿè¦šå…¥åŠ›ã®ç‰¹å¾´ã«å¿œã˜ãŸé‹å‹•ç”Ÿæˆ
        for i, sense in enumerate(sensory_input):
            if i < len(motor_response):
                motor_response[i*2:(i+1)*2] = [sense * 0.8, (1-sense) * 0.5]
                
        return motor_response
    
    def test_sensorimotor_prediction(self):
        """æ„Ÿè¦šé‹å‹•äºˆæ¸¬ãƒ†ã‚¹ãƒˆ"""
        print("\næ„Ÿè¦šé‹å‹•äºˆæ¸¬ãƒ†ã‚¹ãƒˆ:")
        test_sensory = [np.array([0.8, 0.2, 0.6, 0.1, 0.9]),
                       np.array([0.1, 0.7, 0.3, 0.8, 0.2]),
                       np.array([0.5, 0.5, 0.5, 0.5, 0.5])]
        
        for i, sensory in enumerate(test_sensory):
            test_input = np.concatenate([sensory, np.zeros(10)])
            bmu = self.som.find_bmu(test_input)
            print(f"  æ„Ÿè¦šãƒ‘ã‚¿ãƒ¼ãƒ³{i+1}: BMUä½ç½®={bmu}")


class AutonomousMeaningGeneration:
    """è‡ªå¾‹çš„æ„å‘³ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ """
    def __init__(self):
        self.factory = ConsciousnessFactory()
        self.meaning_history = []
        self.context_memory = []
        
    def generate_contextual_meaning(self, environmental_data, action_data):
        """æ–‡è„ˆã«åŸºã¥ãæ„å‘³ç”Ÿæˆ"""
        print("\n=== è‡ªå¾‹çš„æ„å‘³ç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹ ===")
        print("ç’°å¢ƒ-è¡Œå‹•-æ„è­˜ã®ç›¸äº’ä½œç”¨ã‹ã‚‰æ„å‘³ã‚’å‰µç™ºä¸­...")
        
        meanings = []
        for step, (env_data, action) in enumerate(zip(environmental_data[:10], action_data[:10])):
            # æ„è­˜çŠ¶æ…‹ã®å‰µç™ºçš„ç”Ÿæˆ
            consciousness_aggregate = self.factory.create_emergent_consciousness_state(
                environmental_input=env_data,
                prediction_errors=[0.1, 0.05, 0.02],
                coupling_strength=0.7
            )
            
            # æ„å‘³ã®è‡ªå¾‹çš„ç”Ÿæˆ
            meaning = self._extract_meaning_from_consciousness(
                consciousness_aggregate, env_data, action
            )
            
            meanings.append(meaning)
            
            if step % 3 == 0:
                print(f"ã‚¹ãƒ†ãƒƒãƒ— {step:2d}: '{meaning}' "
                      f"(Î¦={consciousness_aggregate.phi_value.value:.2f})")
        
        print(f"âœ… ç”Ÿæˆã•ã‚ŒãŸæ„å‘³ã®ç¨®é¡: {len(set(meanings))}")
        return meanings
    
    def _extract_meaning_from_consciousness(self, consciousness_state, env_data, action):
        """æ„è­˜çŠ¶æ…‹ã‹ã‚‰æ„å‘³ã‚’æŠ½å‡º"""
        phi_level = consciousness_state.phi_value.value
        env_complexity = np.std(env_data)
        action_intensity = np.linalg.norm(action)
        
        if phi_level > 1.0 and env_complexity > 0.3:
            return "è¤‡é›‘ç’°å¢ƒã§ã®é«˜æ¬¡æ„è­˜æ´»å‹•"
        elif action_intensity > 0.3:
            return "èƒ½å‹•çš„ç’°å¢ƒæ¢ç´¢"
        elif env_complexity < 0.1:
            return "å®‰å®šç’°å¢ƒã§ã®ç¶­æŒæ´»å‹•"
        else:
            return "é©å¿œçš„ç’°å¢ƒå¿œç­”"


def run_complete_enactive_experiment():
    """å®Œå…¨ã‚¨ãƒŠã‚¯ãƒ†ã‚£ãƒ–å­¦ç¿’å®Ÿé¨“"""
    print("ğŸ§  ã‚¨ãƒŠã‚¯ãƒ†ã‚£ãƒ–æ„è­˜ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ V3.0")
    print("   å®Œå…¨ã‚¨ãƒŠã‚¯ãƒ†ã‚£ãƒ–å­¦ç¿’å®Ÿé¨“")
    print("=" * 50)
    
    start_time = time.time()
    
    # 1. ã‚¨ãƒŠã‚¯ãƒ†ã‚£ãƒ–å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ 
    print("ã€1/3ã€‘ç’°å¢ƒç›¸äº’ä½œç”¨å­¦ç¿’")
    enactive_system = EnactiveLearningSystem()
    action_results = enactive_system.enactive_learning_cycle(30)
    
    # 2. æ„Ÿè¦šé‹å‹•çµ±åˆ
    print("\nã€2/3ã€‘æ„Ÿè¦šé‹å‹•çµ±åˆ")
    integration = SensoriMotorIntegration()
    integration.learn_sensorimotor_patterns(20)
    integration.test_sensorimotor_prediction()
    
    # 3. æ„å‘³ç”Ÿæˆ
    print("\nã€3/3ã€‘è‡ªå¾‹çš„æ„å‘³ç”Ÿæˆ")
    meaning_gen = AutonomousMeaningGeneration()
    env_data = [np.random.rand(10) for _ in range(15)]
    meanings = meaning_gen.generate_contextual_meaning(env_data, action_results[-15:])
    
    # çµæœã‚µãƒãƒªãƒ¼
    elapsed_time = time.time() - start_time
    print("\n" + "=" * 50)
    print("ã€ã‚¨ãƒŠã‚¯ãƒ†ã‚£ãƒ–å­¦ç¿’å®Ÿé¨“çµæœã€‘")
    print("-" * 30)
    print(f"âœ… å®Ÿè¡Œæ™‚é–“: {elapsed_time:.2f}ç§’")
    print(f"âœ… ç’°å¢ƒç›¸äº’ä½œç”¨ã‚µã‚¤ã‚¯ãƒ«: {len(action_results)}")
    print(f"âœ… ç”Ÿæˆã•ã‚ŒãŸæ„å‘³: {set(meanings)}")
    print(f"âœ… å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ : NGC-Learnçµ±åˆã‚¨ãƒ³ã‚¸ãƒ³")
    print("\nğŸ§ âœ¨ ã‚¨ãƒŠã‚¯ãƒ†ã‚£ãƒ–å­¦ç¿’å®Œäº†")
    print("     çœŸã®èªçŸ¥çš„ç›¸äº’ä½œç”¨ãƒ—ãƒ­ã‚»ã‚¹ã‚’ä½“é¨“ã—ã¾ã—ãŸ")
    print("=" * 50)
    
    return {
        'action_results': action_results,
        'meanings': meanings,
        'execution_time': elapsed_time
    }


if __name__ == "__main__":
    results = run_complete_enactive_experiment()