#!/usr/bin/env python3
"""
æ„è­˜åˆ†æã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§ãƒ†ã‚­ã‚¹ãƒˆã‚’å—ã‘å–ã‚Šã€æ„è­˜åˆ†æã‚’å®Ÿè¡Œã™ã‚‹ã€‚
"""

import sys
import numpy as np
sys.path.append('..')

from text_consciousness_features import PhenomenologicalTextAnalyzer, analyze_text_consciousness
from domain.factories.consciousness_factory import ConsciousnessFactory
from ngc_learn_adapter import HybridPredictiveCodingAdapter
from domain.value_objects.precision_weights import PrecisionWeights


def process_single_text(text: str):
    """å˜ä¸€ãƒ†ã‚­ã‚¹ãƒˆã®æ„è­˜åˆ†æ"""
    print(f"ğŸ§  ã‚¨ãƒŠã‚¯ãƒ†ã‚£ãƒ–æ„è­˜ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ V3.0")
    print(f"   ãƒ†ã‚­ã‚¹ãƒˆæ„è­˜åˆ†æã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 50)
    
    # ç¾è±¡å­¦çš„ç‰¹å¾´é‡åˆ†æ
    analyzer = PhenomenologicalTextAnalyzer()
    features, feature_dict, interpretation = analyze_text_consciousness(text, verbose=False)
    
    # æ„è­˜çŠ¶æ…‹ç”Ÿæˆ
    factory = ConsciousnessFactory()
    
    # äºˆæ¸¬èª¤å·®ã¨çµåˆå¼·åº¦ã®è¨ˆç®—
    variance = np.var(features)
    error_base = max(0.01, variance * 2)
    prediction_errors = [error_base * 1.5, error_base * 1.0, error_base * 0.5]
    
    active_features = np.sum(features > 0.1)
    coupling_strength = 0.3 + (active_features / 10) * 0.7
    coupling_strength = min(coupling_strength, 1.0)
    
    consciousness_state = factory.create_emergent_consciousness_state(
        environmental_input=features,
        prediction_errors=prediction_errors,
        coupling_strength=coupling_strength
    )
    
    # äºˆæ¸¬å‡¦ç†
    adapter = HybridPredictiveCodingAdapter(3, 10)
    precision_weights = PrecisionWeights(np.array([1.0, 0.8, 0.6]))
    prediction_state = adapter.process_input(features, precision_weights)
    
    # æ„å‘³ç”Ÿæˆ
    phi = consciousness_state.phi_value.value
    dominant_feature_idx = np.argmax(features)
    
    meaning_categories = [
        "å¿—å‘çš„æ€è€ƒ", "æ™‚é–“çš„çœå¯Ÿ", "èº«ä½“çš„ä½“é¨“", "ç¤¾ä¼šçš„äº¤æµ", "ç›´æ„Ÿçš„ç†è§£",
        "å‰µé€ çš„æ€è€ƒ", "æ—¥å¸¸çš„ä½“é¨“", "è‡ªç„¶ãªæµã‚Œ", "æ–‡è„ˆçš„ç†è§£", "å€‹äººçš„ä½“é¨“"
    ]
    
    base_meaning = meaning_categories[dominant_feature_idx]
    
    if phi > 1.0:
        depth = "é«˜æ¬¡æ„è­˜"
    elif phi > 0.5:
        depth = "ä¸­ç¨‹åº¦æ„è­˜"
    elif phi > 0.2:
        depth = "åŸºæœ¬æ„è­˜"
    else:
        depth = "å‰æ„è­˜"
    
    complexity = "è¤‡é›‘" if len(text.split()) > 10 else "ã‚·ãƒ³ãƒ—ãƒ«"
    generated_meaning = f"{depth}çš„{base_meaning}ï¼ˆ{complexity}ãªè¡¨ç¾ï¼‰"
    
    # çµæœè¡¨ç¤º
    print(f"ğŸ“ å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ:")
    print(f"   '{text}'")
    print()
    
    print(f"ğŸ§  æ„è­˜åˆ†æçµæœ:")
    print(f"   Î¦å€¤ (çµ±åˆæƒ…å ±): {phi:.4f}")
    print(f"   æ„è­˜ãƒ¬ãƒ™ãƒ«: {consciousness_state.consciousness_level:.3f}")
    print(f"   äºˆæ¸¬èª¤å·®: {prediction_state.total_error:.4f}")
    print(f"   çµåˆå¼·åº¦: {coupling_strength:.3f}")
    print()
    
    print(f"ğŸ” ç¾è±¡å­¦çš„è§£é‡ˆ:")
    print(f"   {interpretation}")
    print()
    
    print(f"ğŸ’­ ç”Ÿæˆã•ã‚ŒãŸæ„å‘³:")
    print(f"   {generated_meaning}")
    print()
    
    print(f"ğŸ“Š ç‰¹å¾´é‡è©³ç´°:")
    explanations = analyzer.get_feature_explanations()
    for i, (name, value) in enumerate(feature_dict.items()):
        bar = "â–ˆ" * int(value * 20) + "â–‘" * (20 - int(value * 20))
        print(f"   {name:<12}: {bar} {value:.3f}")
    print()
    
    print("=" * 50)
    print("âœ… æ„è­˜åˆ†æå®Œäº†")
    
    return {
        'phi_value': phi,
        'consciousness_level': consciousness_state.consciousness_level,
        'generated_meaning': generated_meaning,
        'features': features,
        'interpretation': interpretation
    }


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python test_consciousness_analysis.py \"ãƒ†ã‚­ã‚¹ãƒˆ\"")
        print("ä¾‹: python test_consciousness_analysis.py \"ç§ã¯ä»Šæ—¥ã€ç¾ã—ã„å¤•æ—¥ã‚’è¦‹ã¦ã„ã¾ã™ã€‚\"")
        return
    
    input_text = sys.argv[1]
    result = process_single_text(input_text)


if __name__ == "__main__":
    main()