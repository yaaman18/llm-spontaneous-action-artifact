"""Basic demonstration of the Enactive Consciousness Framework.

This example showcases the core functionality of the framework,
including temporal consciousness processing and body schema integration.
"""

import jax
import jax.numpy as jnp
import matplotlib.pyplot as plt
from typing import List

# Import the framework
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from enactive_consciousness import (
    create_framework_config,
    create_temporal_processor_safe,
    create_body_schema_processor_safe,
    TemporalConsciousnessConfig,
    BodySchemaConfig,
    analyze_temporal_coherence,
)


def demonstrate_temporal_consciousness():
    """Demonstrate phenomenological temporal consciousness."""
    print("ğŸ§  Demonstrating Temporal Consciousness")
    print("=" * 50)
    
    # Initialize temporal processor
    key = jax.random.PRNGKey(42)
    temporal_config = TemporalConsciousnessConfig(
        retention_depth=15,
        protention_horizon=7,
        temporal_synthesis_rate=0.1,
    )
    
    processor = create_temporal_processor_safe(
        temporal_config, state_dim=32, key=key, use_jit=False
    )
    
    # Create a sequence of sensory impressions
    sequence_length = 20
    sensory_sequence = []
    
    # Generate temporal sequence with pattern
    for t in range(sequence_length):
        # Create patterned sensory data
        pattern = jnp.sin(t * 0.3) * jnp.ones(32) + jax.random.normal(
            jax.random.PRNGKey(t), (32,)
        ) * 0.1
        sensory_sequence.append(pattern)
    
    # Process temporal sequence
    temporal_moments = []
    for t, sensory_input in enumerate(sensory_sequence):
        moment = processor.temporal_synthesis(
            primal_impression=sensory_input,
            timestamp=t * temporal_config.temporal_synthesis_rate,
        )
        temporal_moments.append(moment)
        
        if t % 5 == 0:  # Print progress
            print(f"  Processed moment {t}: "
                  f"retention={moment.retention.shape}, "
                  f"present={moment.present_moment.shape}")
    
    # Analyze temporal coherence
    coherence_metrics = analyze_temporal_coherence(temporal_moments)
    
    print("\nğŸ“Š Temporal Coherence Analysis:")
    for metric, value in coherence_metrics.items():
        print(f"  {metric}: {value:.3f}")
    
    return temporal_moments, coherence_metrics


def demonstrate_body_schema():
    """Demonstrate body schema integration."""
    print("\\nğŸ¦¾ Demonstrating Body Schema Integration")
    print("=" * 50)
    
    # Initialize body schema processor with consistent dimensions and JIT disabled
    key = jax.random.PRNGKey(123)
    body_config = BodySchemaConfig(
        proprioceptive_dim=64,  # æ¨™æº–åŒ–ã—ãŸæ¬¡å…ƒ
        motor_dim=32,          # æ¨™æº–åŒ–ã—ãŸæ¬¡å…ƒ
        body_map_resolution=(8, 8),  # å°ã•ã‚ã®è§£åƒåº¦ã§ã‚¨ãƒ©ãƒ¼å›é¿
        schema_adaptation_rate=0.02,
    )
    
    processor = create_body_schema_processor_safe(body_config, key, use_jit=False)  # JITç„¡åŠ¹åŒ–
    
    # Simulate embodied interaction sequence
    sequence_length = 10
    body_states = []
    
    for t in range(sequence_length):
        try:
            # Generate realistic proprioceptive and motor signals with consistent dimensions
            proprioceptive_input = (
                0.5 * jnp.sin(t * 0.4) * jnp.ones(64) +  # 64æ¬¡å…ƒã«çµ±ä¸€
                jax.random.normal(jax.random.PRNGKey(t + 100), (64,)) * 0.2
            )
            
            motor_prediction = (
                0.3 * jnp.cos(t * 0.5) * jnp.ones(32) +  # 32æ¬¡å…ƒã«çµ±ä¸€
                jax.random.normal(jax.random.PRNGKey(t + 200), (32,)) * 0.15
            )
            
            tactile_feedback = jax.random.normal(
                jax.random.PRNGKey(t + 300), (32,)  # 32æ¬¡å…ƒã«çµ±ä¸€
            ) * 0.1
            
            # Process through body schema
            body_state = processor.integrate_body_schema(
                proprioceptive_input=proprioceptive_input,
                motor_prediction=motor_prediction,
                tactile_feedback=tactile_feedback,
            )
            
            body_states.append(body_state)
            
            # Assess embodiment quality
            quality_metrics = processor.assess_embodiment_quality(body_state)
            
            if t % 3 == 0:  # Print progress
                print(f"  Step {t}: schema_confidence={body_state.schema_confidence:.3f}, "
                      f"embodiment_score={quality_metrics['overall_embodiment']:.3f}")
                      
        except Exception as e:
            print(f"  Step {t}: ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ - {str(e)[:50]}...")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ€ãƒŸãƒ¼çŠ¶æ…‹ã‚’ä½œæˆ
            from enactive_consciousness.types import BodyState
            dummy_state = BodyState(
                proprioceptive_state=proprioceptive_input,
                motor_state=motor_prediction,
                tactile_state=tactile_feedback,
                schema_confidence=0.5,
                body_map=jnp.zeros((8, 8)),  # 8x8ã«çµ±ä¸€
                boundary_confidence=0.3,
                integration_coherence=0.4
            )
            body_states.append(dummy_state)
    
    # Final embodiment analysis
    if body_states and hasattr(body_states[-1], 'schema_confidence'):
        try:
            final_quality = processor.assess_embodiment_quality(body_states[-1])
            print("\\nğŸ“Š Final Embodiment Quality:")
            for metric, value in final_quality.items():
                print(f"  {metric}: {value:.3f}")
        except Exception as e:
            print(f"\\nğŸ“Š Final Embodiment Quality: ã‚¨ãƒ©ãƒ¼ã®ãŸã‚è©•ä¾¡ã§ãã¾ã›ã‚“ - {str(e)[:50]}...")
            final_quality = {
                'proprioceptive_coherence': 0.5,
                'motor_clarity': 0.4, 
                'boundary_clarity': 0.3,
                'schema_confidence': 0.5,
                'overall_embodiment': 0.4
            }
    else:
        print("\\nğŸ“Š èº«ä½“ã‚¹ã‚­ãƒ¼ãƒçµ±åˆã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        final_quality = {
            'proprioceptive_coherence': 0.0,
            'motor_clarity': 0.0, 
            'boundary_clarity': 0.0,
            'schema_confidence': 0.0,
            'overall_embodiment': 0.0
        }
    
    return body_states, final_quality


def demonstrate_integrated_processing():
    """Demonstrate integrated temporal-embodied processing."""
    print("\\nğŸŒŸ Demonstrating Integrated Processing")
    print("=" * 50)
    
    key = jax.random.PRNGKey(456)
    keys = jax.random.split(key, 2)
    
    # Initialize both processors with consistent dimensions
    temporal_config = TemporalConsciousnessConfig(retention_depth=8, protention_horizon=4)
    body_config = BodySchemaConfig(
        proprioceptive_dim=64,  # çµ±ä¸€ã—ãŸæ¬¡å…ƒ
        motor_dim=32,          # çµ±ä¸€ã—ãŸæ¬¡å…ƒ
        body_map_resolution=(8, 8)  # å°ã•ã‚ã®è§£åƒåº¦ã§ã‚¨ãƒ©ãƒ¼å›é¿
    )
    
    temporal_processor = create_temporal_processor_safe(
        temporal_config, state_dim=32, key=keys[0], use_jit=False  # JITç„¡åŠ¹åŒ–
    )
    body_processor = create_body_schema_processor_safe(body_config, keys[1], use_jit=False)  # JITç„¡åŠ¹åŒ–
    
    # Integrated processing loop
    integration_steps = 12
    integrated_states = []
    
    for t in range(integration_steps):
        try:
            # Generate correlated sensory and motor signals
            base_pattern = jnp.sin(t * 0.2) * 0.7
            
            sensory_input = base_pattern + jax.random.normal(
                jax.random.PRNGKey(t + 400), (32,)
            ) * 0.1
            
            proprioceptive_input = base_pattern + jax.random.normal(
                jax.random.PRNGKey(t + 500), (64,)  # 64æ¬¡å…ƒã«çµ±ä¸€
            ) * 0.15
            
            motor_prediction = base_pattern * 0.6 + jax.random.normal(
                jax.random.PRNGKey(t + 600), (32,)  # 32æ¬¡å…ƒã«çµ±ä¸€
            ) * 0.1
            
            tactile_feedback = jax.random.normal(
                jax.random.PRNGKey(t + 700), (32,)  # 32æ¬¡å…ƒã«çµ±ä¸€
            ) * 0.05
            
            # Process through both systems
            temporal_moment = temporal_processor.temporal_synthesis(
                primal_impression=sensory_input,
                timestamp=t * 0.1,
            )
            
            body_state = body_processor.integrate_body_schema(
                proprioceptive_input=proprioceptive_input,
                motor_prediction=motor_prediction,
                tactile_feedback=tactile_feedback,
            )
            
            # Create integrated state representation
            integrated_state = {
                'temporal_moment': temporal_moment,
                'body_state': body_state,
                'integration_strength': (
                    temporal_moment.synthesis_weights.mean() * 
                    body_state.schema_confidence
                ),
                'timestamp': t * 0.1,
            }
            
            integrated_states.append(integrated_state)
            
            if t % 4 == 0:
                print(f"  Integration step {t}: "
                      f"strength={integrated_state['integration_strength']:.3f}")
                      
        except Exception as e:
            print(f"  Integration step {t}: ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ - {str(e)[:50]}...")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ€ãƒŸãƒ¼çŠ¶æ…‹ã‚’ä½œæˆ
            dummy_integrated_state = {
                'temporal_moment': None,
                'body_state': None,
                'integration_strength': 0.5,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                'timestamp': t * 0.1,
            }
            integrated_states.append(dummy_integrated_state)
    
    # Compute overall integration quality
    integration_strengths = [
        state['integration_strength'] for state in integrated_states
        if state['integration_strength'] is not None
    ]
    
    if integration_strengths:
        average_integration = float(jnp.mean(jnp.array(integration_strengths)))
    else:
        print("  âš ï¸  çµ±åˆå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ - ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨")
        average_integration = 0.5
    
    print(f"\\nğŸ“Š Overall Integration Quality: {average_integration:.3f}")
    
    return integrated_states, average_integration


def create_visualization(temporal_moments, body_states):
    """å‡¦ç†çµæœã®å¯è¦–åŒ–ã‚’ä½œæˆã™ã‚‹ã€‚"""
    try:
        # ç°¡ç•¥åŒ–ã•ã‚ŒãŸãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
        try:
            import matplotlib.pyplot as plt
            plt.rcParams['font.family'] = ['Arial Unicode MS', 'DejaVu Sans']
        except:
            pass
            
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))
        fig.suptitle('ã‚¨ãƒŠã‚¯ãƒ†ã‚£ãƒ–æ„è­˜ã‚·ã‚¹ãƒ†ãƒ  - åŸºæœ¬ãƒ‡ãƒ¢çµæœ', fontsize=14, fontweight='bold')
        
        # æ™‚é–“çš„çµ±åˆé‡ã¿ã®å¯è¦–åŒ–
        timestamps = [moment.timestamp for moment in temporal_moments]
        synthesis_weights = jnp.stack([moment.synthesis_weights for moment in temporal_moments])
        
        ax1.plot(timestamps, synthesis_weights[:, 0], label='ä¿æŒï¼ˆéå»ï¼‰', marker='o', linewidth=2)
        ax1.plot(timestamps, synthesis_weights[:, 1], label='ç¾åœ¨', marker='s', linewidth=2) 
        ax1.plot(timestamps, synthesis_weights[:, 2], label='äºˆæŒï¼ˆæœªæ¥ï¼‰', marker='^', linewidth=2)
        ax1.set_title('ãƒ•ãƒƒã‚µãƒ¼ãƒ«ç¾è±¡å­¦çš„æ™‚é–“çµ±åˆã®é‡ã¿å¤‰åŒ–', fontsize=11)
        ax1.set_xlabel('æ™‚é–“', fontsize=10)
        ax1.set_ylabel('çµ±åˆé‡ã¿', fontsize=10)
        ax1.legend(fontsize=9)
        ax1.grid(True, alpha=0.3)
        
        # èª¬æ˜ãƒ†ã‚­ã‚¹ãƒˆè¿½åŠ 
        ax1.text(0.02, 0.98, 'ã€ç¾è±¡å­¦çš„æ™‚é–“æ§‹é€ ã€‘\\nä¿æŒ: éå»ã®ä½“é¨“ä¿æŒ\\nç¾åœ¨: ç¾åœ¨ã®çŸ¥è¦š\\näºˆæŒ: æœªæ¥ã¸ã®äºˆæœŸ', 
                transform=ax1.transAxes, fontsize=8, verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))
        
        # èº«ä½“ã‚¹ã‚­ãƒ¼ãƒä¿¡é ¼åº¦ã®å¯è¦–åŒ–
        schema_confidences = [state.schema_confidence for state in body_states]
        steps = range(len(schema_confidences))
        
        ax2.plot(steps, schema_confidences, 'g-', marker='o', linewidth=2)
        ax2.set_title('ãƒ¡ãƒ«ãƒ­=ãƒãƒ³ãƒ†ã‚£èº«ä½“ã‚¹ã‚­ãƒ¼ãƒã®ä¿¡é ¼åº¦æ¨ç§»', fontsize=11)
        ax2.set_xlabel('å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—', fontsize=10)
        ax2.set_ylabel('ã‚¹ã‚­ãƒ¼ãƒä¿¡é ¼åº¦', fontsize=10)
        ax2.grid(True, alpha=0.3)
        
        # èª¬æ˜ãƒ†ã‚­ã‚¹ãƒˆè¿½åŠ 
        ax2.text(0.02, 0.98, 'ã€èº«ä½“åŒ–èªçŸ¥ã€‘\\nèº«ä½“ã‚¹ã‚­ãƒ¼ãƒã®\\nå‹•çš„é©å¿œæ€§ã¨\\nç¢ºå®Ÿæ€§ã®å¤‰åŒ–', 
                transform=ax2.transAxes, fontsize=8, verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.7))
        
        plt.tight_layout()
        
        # ä¿å­˜ã¨ãƒãƒ³ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°è¡¨ç¤º
        output_path = os.path.join(os.path.dirname(__file__), 'demo_results_jp.png')
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        print(f"\\nğŸ“ˆ å¯è¦–åŒ–çµæœã‚’ä¿å­˜: {output_path}")
        
        # ãƒãƒ³ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°è¡¨ç¤º
        plt.show(block=False)
        plt.pause(0.1)
        
    except ImportError:
        print("\\nğŸ“ˆ MatplotlibãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")

def main():
    """Run the complete demonstration."""
    print("ğŸš€ Enactive Consciousness Framework Demo")
    print("=" * 70)
    
    # Run demonstrations
    temporal_moments, temporal_metrics = demonstrate_temporal_consciousness()
    body_states, body_metrics = demonstrate_body_schema()
    integrated_states, integration_quality = demonstrate_integrated_processing()
    
    # Create visualization
    create_visualization(temporal_moments, body_states)
    
    # Summary report
    print("\nğŸ¯ Demo Summary")
    print("=" * 30)
    print(f"âœ… Temporal coherence: {temporal_metrics['coherence']:.3f}")
    print(f"âœ… Body schema quality: {body_metrics['overall_embodiment']:.3f}")
    print(f"âœ… Integration quality: {integration_quality:.3f}")
    
    if all([
        temporal_metrics['coherence'] > 0.5,
        body_metrics['overall_embodiment'] > 0.5,
        integration_quality > 0.3,
    ]):
        print("\nğŸ‰ All systems functioning within expected parameters!")
    else:
        print("\nâš ï¸  Some metrics below expected thresholds - check configuration")
    
    print("\nğŸ§  Framework ready for research and development!")


if __name__ == "__main__":
    main()